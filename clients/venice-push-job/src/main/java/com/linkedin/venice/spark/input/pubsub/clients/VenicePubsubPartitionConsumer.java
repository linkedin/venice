package com.linkedin.venice.spark.input.pubsub.clients;

//import com.linkedin.venice.pubsub.PubSubTopicRepository;
//import com.linkedin.venice.pubsub.adapter.kafka.admin.ApacheKafkaAdminAdapter;
//import com.linkedin.venice.pubsub.adapter.kafka.consumer.ApacheKafkaConsumerAdapter;
//import com.linkedin.venice.spark.input.pubsub.table.VenicePubsubInputPartition;
//import java.util.Properties;

public class VenicePubsubPartitionConsumer {
  // potentially future home of consumer if we decide to factor it out of the VenicePubsubPartitionReader

  // private final Properties configBag;
  // private final VenicePubsubInputPartition inputPartition;
  // private final PubSubTopicRepository pubSubTopicRepository = new PubSubTopicRepository();
  // private ApacheKafkaConsumerAdapter consumer;
  // private ApacheKafkaAdminAdapter admin;
  //
  // public VenicePubsubPartitionConsumer(Properties configBag, VenicePubsubInputPartition inputPartition) {
  // this.configBag = configBag;
  // this.inputPartition = inputPartition;
  // String consumerName = "VeniceSpark_p-" + inputPartition.getPartitionNumber() + "_"
  // + inputPartition.getSegmentStartOffset() + "-" + inputPartition.getSegmentEndOffset();
  //
  // }
}
