---
layout: default
title: Venice P2P Transfer Bootstrapping Quickstart
parent: Quickstart
permalink: /docs/quickstart/quickstart_P2P_transfer_bootstrapping
---


# Venice P2P Transfer Bootstrapping Architecture

**High-Performance Peer-to-Peer Data Bootstrap**

*Accelerating Venice Node Deployment Through Direct Peer-to-Peer RocksDB Snapshot Transfer*

---

## ğŸš¨ Problem & Solution

### The Problem

**Bootstrap Bottlenecks**
- **Kafka-Only Recovery:** All nodes bootstrap exclusively from Kafka brokers
- **Resource Intensive:** Time-consuming process during cluster recovery, inefficient for consuming messages from the PubSub system under high-update workloads
- **Scalability Limits:** Broker capacity becomes recovery bottleneck

**Real-World Impact**
- Extended MTTR (Mean Time to Restore or Repair) during outages
- Cascading broker overload
- Slower cluster expansion
- Increased operational overhead

### ğŸ’¡ The Solution

**Direct P2P Transfer**
- **Peer-to-Peer:** Direct node-to-node data transfer
- **RocksDB Snapshots:** Consistent point-in-time data copies
- **Intelligent Fallback:** Automatic Kafka Ingestion recovery on failure
- **Low Risk:** Low Deployment Risk in DaVinci client

**Key Benefits**
- Faster node recovery and scaling
- Reduced Kafka broker load


---

## ğŸ—ï¸ System Architecture Flow

### Venice Blob Transfer Complete Flow

```
                           Venice Blob Transfer Complete Flow

Step 1: Peer Discovery
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Discovery Request   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Query Helix/ZK     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client Node â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Discovery   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Metadata    â”‚
â”‚ (Needs Data)â”‚                      â”‚ Service     â”‚                     â”‚ Repository  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       ^                                     â”‚                                   â”‚
       â”‚                                     â”‚ Return Host List                  â”‚
       â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Host List:  â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ [host1,     â”‚
                                      â”‚  host2,     â”‚
                                      â”‚  host3...]  â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Sequential Host Attempts
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  T1:Try Host 1  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” 
â”‚ Client Node â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Server A    â”‚ 
â”‚             â”‚ <â”€â”€ FAIL â”€â”€â”€â”€â”€â”€ â”‚ (No Data/   â”‚                 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  Busy)      â”‚                
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 
                 T2:Try Host 2  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Server B    â”‚ 
                <â”€â”€ FAIL â”€â”€â”€â”€â”€â”€ â”‚ Table Formatâ”‚
                                â”‚  not Match  â”‚              
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       

                 T3:Try Host 3  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Server C    â”‚ 
                                â”‚ (Not busy,  â”‚               
                                â”‚Format Match)â”‚              
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     
                                         
Step 3: Start Transfer                   
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       
â”‚ Client Node    â”‚ 
â”‚                â”‚
â”‚  Receives:     â”‚ <â”€â”€ 1.1 File: file1.sst â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Files      â”‚ <â”€â”€ 1.2 File: file2.sst â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ Server C    â”‚
â”‚                â”‚ <â”€â”€ 1.3 File: MANIFEST_00 â”€â”€â”€â”€â”€â”€â”€â”€ â”‚             â”‚
â”‚  2. Metadata   â”‚ <â”€â”€ 2. Metadata â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  3. COMPLETE   â”‚ <â”€â”€ 3. COMPLETE Flag â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 4: Client Processing after recevie COMPLETE flag

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Validate Files     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Atomic Rename     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client Node â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Temp Folder â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Partition   â”‚
â”‚             â”‚  (MD5)              â”‚/store/temp_ â”‚    (tempâ†’partition)  â”‚ Folder      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     | p1/         |                      â”‚ /store/p1/  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 5: Kafka Ingestion Fallback (Always Happens)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Resume/Fill Gap    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client Node â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Kafka       â”‚
â”‚             â”‚  From snapshot      â”‚ Ingestion   â”‚
â”‚             â”‚  offset to latest   â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

**Step 1: Peer Discovery**
- **Venice Server:** Query Helix CustomizedViewRepository for COMPLETED nodes
- **DaVinci Application:** Query DaVinci push job report for ready-to-serve nodes

**Step 2: P2P Transfer in Client Side**
```
Connectivity Check â”€â”€â”€â”€> Peer Selection â”€â”€â”€â”€> Sequential Request
      â†“                         â†“                      â†“
Parallel connection       Filter & shuffle      Try peers until
check with caching      connectable hosts      success or exhaust
```

**Step 3: Data Transfer**
```
Snapshot Creation â”€â”€â”€â”€> File Streaming â”€â”€â”€â”€>  Metadata Sync
       â†“                       â†“                  â†“
Server creates         Chunked transfer      Offset + Version State
RocksDB snapshot      with MD5 validation     after files complete
```
**Step 4: Completion**
- **Success Path:** After validating all files, atomically rename the temp directory to the partition directory, then initiate Kafka ingestion to synchronize any remaining offset gap.
- **Fallback Path:** If any error occurs, clean up the temp directory and retry with the next peer; if all peers fail, back to Kafka bootstrap from the beginning.

### Key Components

- **DefaultIngestionBackend** - Bootstrap orchestration entry point
- **NettyP2PBlobTransferManager** - P2P transfer coordinator
- **BlobSnapshotManager** - Server-side snapshot lifecycle
- **NettyFileTransferClient** - High-performance client


## ğŸ“¥ Client-Side Process

### Process Flow

```
1. Discover Peers â†’ 2. Check Connectivity â†’ 3. Request Data â†’ 4. Fallback to Kafka
```

### ğŸ” Step 1: Peer Discovery

**Venice Server:**
- Query Helix CustomizedViewRepository
- Find COMPLETED nodes
- Filter by store/version/partition

**DaVinci Application:**
- Query DaVinci push job report
- Find ready-to-serve nodes
- Extract available peer list

### ğŸ”— Step 2: Connectivity Checking
Smart Caching Strategy due to large peer sets:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Purge Stale â”‚ â†’ â”‚ Filter Bad  â”‚ â†’ â”‚ Check Hosts in      â”‚ â†’ â”‚ Update Cacheâ”‚
â”‚ Records     â”‚   â”‚ Hosts       â”‚   â”‚Parallel Connectivityâ”‚   â”‚ Results     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          
```

- **Parallel Testing:** Multiple host connections simultaneously
- **Smart Caching:** Remember good/bad hosts with timestamps
- **Timeout Management:** 1-minute connectivity check limit

### ğŸ“¦ Step 3: Sequential Data Request

```
For Each Peer (Shuffled List):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Send Request  â”‚ â†’ â”‚  Receive Data   â”‚ â†’ â”‚  Receive        â”‚ â†’ â”‚  Receive        â”‚ â†’ â”‚   Validate      â”‚ â†’ â”‚  Rename Temp    â”‚
â”‚    HTTP GET     â”‚   â”‚  File Chunks    â”‚   â”‚  Metadata       â”‚   â”‚ COMPLETE_FLAG   â”‚   â”‚      MD5        â”‚   â”‚ to Partition Dirâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


### ğŸš¨ Error Handling Details in different Scenarios

**Connection Failures (VenicePeersConnectionException)**
- Network timeout
- SSL handshake failure
- Host unreachable
- **Action:** Try next peer

**File Not Found (VeniceBlobTransferFileNotFoundException)**
- Snapshot missing
- Stale snapshot
- Server too busy, reject with 429 errors
- **Action:** Try next peer

**Transfer Errors (Data Integrity Issues)**
- Checksum mismatch
- File size mismatch
- Network interruption: Server initiates deployment or shuts down unexpectedly
- **Action:** Cleanup + next peer

### ğŸ§¹ Comprehensive Cleanup Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Force Flush â”‚ â†’ â”‚ Close File  â”‚ â†’ â”‚ Delete      â”‚ â†’ â”‚ Reset       â”‚
â”‚ File Channelâ”‚   â”‚ Handles     â”‚   â”‚ Partial Dir â”‚   â”‚ Handler     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Zero Partial State:** Complete cleanup ensures no corruption
- **Handler Reset:** Ready for next peer attempt

### ğŸ”„ Step 4: Kafka Fallback Strategy

**Two-Phase Strategy:**
- **Phase 1 - Blob Transfer:** Rapid bulk data transfer via P2P
- **Phase 2 - Kafka Fill-Gap:** Even if blob transfer fails, deployment continues with Kafka ingestion

**Zero-Risk Design:** After a successful blob transfer, Kafka ingestion always follows to synchronize any data between the snapshot offset and the latest offset, guaranteeing full deployment.

---

## ğŸ“¤ Server-Side Process

### Process Flow

```
1. Request Reception & Validation â†’ 2. Prepare Snapshot & Metadata â†’ 3. File Transfer & Chunking â†’ 4. Metadata Transfer & Completion
```

### â˜‘ï¸ Step 1: Request Reception & Validation

Incoming Request Pipeline:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP GET    â”‚    â”‚ Parse URI   â”‚    â”‚ Validate    â”‚    â”‚ Check       â”‚
â”‚ Request     â”‚ â†’  â”‚ Extract     â”‚ â†’  â”‚ Table       â”‚ â†’  â”‚ Concurrency â”‚
â”‚             â”‚    â”‚ Parameters  â”‚    â”‚ Format      â”‚    â”‚ Limits      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **URI Parsing:** /storeName/version/partition/tableFormat
- **Format Check:** PLAIN_TABLE vs BLOCK_BASED_TABLE match verification
- **Concurrency Control:** Global limit enforcement; reject with 429 if over limit

### ğŸ“Š Step 2: Prepare Snapshot & Metadata

**Snapshot Lifecycle:**
- Check staleness (Configable TTL)
- Verify concurrent user limits
- Create a new snapshot if the existing one is stale or does not exist
- Prepare partition metadata

**Metadata Preparation:**
- Serialization of StoreVersionState (enables synchronization of hybrid store configuration parameters)
- OffsetRecord encapsulation (captures the snapshotâ€™s offset for accurate state synchronization)
- JSON metadata response

### ğŸ“¦ Step 3: File Transfer & Chunking Strategy (Server/Client Single File Transfer Process Details)

**Server-Side Adaptive Chunking Algorithm:**



```
Step 1: File Preparation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Open File for         â”‚   â”‚   Calculate File        â”‚   â”‚   Generate MD5          â”‚   â”‚   Prepare HTTP          â”‚   â”‚   Send Response         â”‚
â”‚     Reading             â”‚   â”‚      Length             â”‚   â”‚     Checksum            â”‚   â”‚    Response             â”‚   â”‚      Headers            â”‚
â”‚                         â”‚ â†’ â”‚                         â”‚ â†’ â”‚                         â”‚ â†’ â”‚                         â”‚ â†’ â”‚                         â”‚
â”‚ Open file in            â”‚   â”‚ Get file size for       â”‚   â”‚ Generate checksum       â”‚   â”‚ Set content headers     â”‚   â”‚ Send headers to         â”‚
â”‚ read-only mode          â”‚   â”‚ response headers        â”‚   â”‚ for validation          â”‚   â”‚ and file metadata       â”‚   â”‚ client first            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Adaptive Chunking Strategy
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   
â”‚   Calculate Optimal     â”‚   â”‚   Create Chunked        â”‚   â”‚   Wrap for HTTP         â”‚   
â”‚     Chunk Size          â”‚   â”‚    File Handler         â”‚   â”‚     Streaming           â”‚  
â”‚ 16KB - 2MB              â”‚ â†’ â”‚                         â”‚ â†’ â”‚                         â”‚ 
â”‚ Determine best chunk    â”‚   â”‚ Set up memory-efficient â”‚   â”‚ Prepare for HTTP        â”‚ 
â”‚ size based on file      â”‚   â”‚ streaming mechanism     â”‚   â”‚ chunked transfer        â”‚ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   

Step 3: Efficient File Streaming
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Stream File Data      â”‚   â”‚   Netty Chunked         â”‚   â”‚   Monitor Transfer      â”‚   â”‚   Complete Transfer     â”‚
â”‚     in Chunks           â”‚   â”‚    Write Handler        â”‚   â”‚      Progress           â”‚   â”‚                         â”‚
â”‚                         â”‚ â†’ â”‚                         â”‚ â†’ â”‚                         â”‚ â†’ â”‚                         â”‚
â”‚ ctx.writeAndFlush()     â”‚   â”‚ Memory-efficient        â”‚   â”‚ Log success/failure     â”‚   â”‚ Ready for next file     â”‚
â”‚ non-blocking write      â”‚   â”‚ file streaming          â”‚   â”‚ per file                â”‚   â”‚ or metadata             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

**Client-Side High-Performance Reception:**




```
Step 1: File Setup
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Parse Headers         â”‚   â”‚   Create Temp Dir       â”‚   â”‚   Create Empty File     â”‚
â”‚                         â”‚   â”‚                         â”‚   â”‚                         â”‚
â”‚ â€¢ Extract filename      â”‚ â†’ â”‚ â€¢ Make /store/temp_p0/  â”‚ â†’ â”‚ â€¢ Create empty file     â”‚
â”‚ â€¢ Extract file size     â”‚   â”‚ â€¢ Delete if exists      â”‚   â”‚ â€¢ Open FileChannel      â”‚
â”‚ â€¢ Extract MD5 hash      â”‚   â”‚                         â”‚   â”‚   in WRITE mode         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Write Data Chunk for each chunk arrived repeatedly
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Receive Network       â”‚   â”‚   Convert to Channel    â”‚   â”‚   Write to File         â”‚
â”‚      Data Chunk         â”‚   â”‚                         â”‚   â”‚                         â”‚
â”‚                         â”‚ â†’ â”‚ â€¢ ByteBuf â†’ Stream      â”‚ â†’ â”‚ â€¢ transferFrom() call   â”‚
â”‚ â€¢ HttpContent arrives   â”‚   â”‚ â€¢ Stream â†’ Channel      â”‚   â”‚                         â”‚
â”‚ â€¢ Extract ByteBuf       â”‚   â”‚                         â”‚   â”‚ â€¢ Update file position  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Step 3: Complete File
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Last Chunk Received   â”‚   â”‚   Flush and Close       â”‚   â”‚   Async Validation      â”‚
â”‚                         â”‚   â”‚                         â”‚   â”‚                         â”‚
â”‚ â€¢ Detect end of file    â”‚ â†’ â”‚ â€¢ Force data to disk    â”‚ â†’ â”‚ â€¢ Submit MD5 check      â”‚
â”‚ â€¢ Validate file size    â”‚   â”‚ â€¢ Close FileChannel     â”‚   â”‚ â€¢ Reset handler state   â”‚
â”‚                         â”‚   â”‚                         â”‚   â”‚ â€¢ Ready for next file   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```
```
Data Flow Transformation at Convert to Channel

Network â†’ ByteBuf â†’ ByteBufInputStream â†’ ReadableByteChannel â†’ FileChannel
   â”‚         â”‚              â”‚                    â”‚               â”‚
   â”‚         â”‚              â”‚                    â”‚               â””â”€ Disk File
   â”‚         â”‚              â”‚                    â””â”€ NIO Channel (efficient)
   â”‚         â”‚              â””â”€ Java Stream (bridge)
   â”‚         â””â”€ Netty Buffer
   â””â”€ Raw network packets

```

### ğŸ“Š Step 4: Metadata Transfer & Completion Protocol

**Critical Ordering for Data Consistency:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Prepare  â”‚   â”‚ 2. Transfer â”‚   â”‚ 3. Send     â”‚   â”‚ 4. Send     â”‚
â”‚ RocksDB     â”‚ â†’ â”‚ All Files   â”‚ â†’ â”‚ Metadata    â”‚â†’  â”‚ COMPLETE    â”‚
â”‚ Snapshot    â”‚   â”‚ (with MD5)  â”‚   â”‚ (Offset +   â”‚   â”‚ Signal      â”‚
â”‚             â”‚   â”‚             â”‚   â”‚ SVS)        â”‚   â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Ordering is Critical:**

âŒ **Wrong Order (Metadata â†’ Files â†’ Complete):**
- Client updates offset records immediately
- If file transfer fails, offset state is corrupted
- Need offset/SVS rollback mechanisms
- Increased error handling complexity and risk

âœ… **Correct Order (Files â†’ Metadata â†’ Complete):**
- Files transferred and validated first
- Metadata only sent after successful file transfer
- Atomic state update on COMPLETE signal
- Less risk consistency guarantee

**Metadata Consistency Protocol:**
- **Metadata:** OffsetRecord + StoreVersionState captured before snapshot creation time
- **JSON Serialization:** Structured metadata transfer with size validation

---
## ğŸŒ Traffic Control

### ğŸš¥ Global Traffic Shaping

**Shared Rate Limiting:** Single GlobalChannelTrafficShapingHandler instance controls bandwidth across ALL blob transfer channels globally

### Traffic Management Strategy

```
Global Control Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Single    â”‚   â”‚  Monitor    â”‚   â”‚  Enforce    â”‚
â”‚ Controller  â”‚ â†’ â”‚ All Channelsâ”‚ â†’ â”‚ Bandwidth   â”‚
â”‚  Instance   â”‚   â”‚ Globally    â”‚   â”‚  Limits     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Write Limit:** Global bytes/sec across all channels
- **Read Limit:** Global bytes/sec across all channels
- **Check Interval:** 1 second monitoring cycle

### Adaptive Throttling System

**Dynamic Rate Adjustment:**
- Increment/Decrement: 20%
- Range: 20% - 200% of base rate
- Separate read/write throttlers
- Idle threshold handling

---

## ğŸ›ï¸ Configuration & Operations

### Configurations

ğŸ“¥ **Receiver/Client Feature Enablement Control**

*Venice Server:*
- Store Level: `blobTransferInServerEnabled`
- Application Level: `blob.transfer.receiver.server.policy`

*DaVinci Application:*
- Store Level: `blobTransferEnabled`

ğŸ“¤ **Sender/Server Feature Enablement Control**

*All Applications:*
- Application Level: `blob.transfer.manager.enabled`

### Performance Tuning Parameters

ğŸªœ **Thresholds**
- **Offset Lag:** Skip blob transfer if not lagged enough
- **Snapshot TTL:** Maintain snapshot freshness
- **Snapshot Cleanup Interval:** Maintain disk storage

ğŸï¸ **Bandwidth Limits**
- **Client Read:** Client side read bytes per sec
- **Service Write:** Server write bytes per sec
- **Adaptive Range:** 20% - 200% of base rate
- **Max Concurrent Snapshot User:** Control server concurrent serve requests load

â° **Timeouts**
- **Transfer Max:** Server side max timeout for transferring files
- **Receive Max:** Client side max timeout for receiving files

---

## ğŸ“‹ Summary

### Venice Blob Transfer: Key Features & Benefits

**ğŸš€ Performance Excellence**
- Intelligent peer discovery and selection
- Fast failover with comprehensive error handling
- High-performance Netty streaming architecture
- Efficient file operations and adaptive chunking

**ğŸ”’ Rock-Solid Reliability**
- Consistent RocksDB snapshots with point-in-time guarantees
- Comprehensive error handling and automatic cleanup
- Data integrity validation with MD5 and size checks
- Automatic Kafka fallback for 100% data coverage

**ğŸ›¡ï¸ Security & Control**
- End-to-end SSL/TLS encryption
- Certificate-based ACL validation
- Global traffic rate limiting and adaptive throttling
- Comprehensive timeout and connection management

**ğŸ”§ Operational Excellence**
- Flexible multi-level configuration
- Automated snapshot lifecycle management
- Graceful degradation and low risk deployment

**Result: Faster node recovery, reduced infrastructure load, improved cluster scalability with enterprise-grade reliability**