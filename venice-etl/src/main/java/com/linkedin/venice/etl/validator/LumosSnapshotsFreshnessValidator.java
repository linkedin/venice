package com.linkedin.venice.etl.validator;

import azkaban.jobExecutor.AbstractJob;
import com.linkedin.venice.exceptions.VeniceException;
import com.linkedin.venice.utils.VeniceProperties;
import java.io.IOException;
import java.util.Comparator;
import java.util.Date;
import java.util.PriorityQueue;
import java.util.Properties;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import org.apache.commons.lang.time.DateUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.PathFilter;
import org.apache.log4j.Logger;

import static com.linkedin.venice.ConfigKeys.*;


/**
 * Lumos Snapshots Freshness Validator is an Azkaban workflow to verify whether
 * the snapshots published by Lumos workflow is fresh or not.
 *
 * The freshness check workflow runs asynchronously after data-publish workflow
 * It checks whether all stores have a new snapshot today in source directory published by Lumos.
 * It checks whether all stores have a snapshot yesterday;
 * If there is a snapshot yesterday, check whether today's the number of records increases compared to yesterday.
 *
 * The workflow will fail if any of the store satisfies one of the following:
 * 1. The store doesn't have snapshots published today
 * 2. The number of records today doesn't increase compared to yesterday
 */
public class LumosSnapshotsFreshnessValidator extends AbstractJob {
  private static final Logger logger = Logger.getLogger(LumosSnapshotsFreshnessValidator.class);

  /**
   * Daily ETL snapshot format is "timestamp-PT-recordNumber"
   */
  private static final String SNAPSHOT_SEPARATOR = "-PT-";
  /**
   * The regex is "\A[0-9]+-PT-[0-9]+\z", which matches the strings like:
   * 1570183273436-PT-558022380
   * 1570269674164-PT-558132495
   */
  private static final Pattern SNAPSHOT_PATTERN = Pattern.compile("\\A[0-9]+" + SNAPSHOT_SEPARATOR + "[0-9]+\\z");

  /**
   * Hadoop Path comparator which puts bigger path in the beginning, so the PriorityQueue will be a max heap
   * and the first element will be the latest snapshot.
   */
  private static final Comparator<FileStatus> SNAPSHOT_COMPARATOR = new Comparator<FileStatus>() {
    @Override
    public int compare(FileStatus o1, FileStatus o2) {
      return -1 * o1.getPath().compareTo(o2.getPath());
    }
  };

  private final VeniceProperties props;

  private Path path;
  private FileSystem fs;
  private PriorityQueue<FileStatus> snapshotQueue;

  public LumosSnapshotsFreshnessValidator(String jobId, Properties vanillaProps) throws Exception {
    super(jobId, logger);
    this.props = new VeniceProperties(vanillaProps);
    logger.info("Constructing " + LumosSnapshotsFreshnessValidator.class.getSimpleName() + ": " + props.toString(true));

    /**
     * the directory that contains the snapshots generated by Gobblin/Lumos pipeline,
     * which are the snapshots in version level
     */
    this.path = new Path(props.getString(ETL_SNAPSHOT_SOURCE_DIR));

    /**
     * gets configured HDFS filesystem for read and write
     */
    try {
      this.fs = FileSystem.get(new Configuration());
    } catch (IOException e) {
      logger.error("Get configured FileSystem implementation failed: ", e);
      throw e;
    }
    /**
     * The priority queue is to sort lumos snapshots by time. The latest snapshot pops first.
     */
    this.snapshotQueue = new PriorityQueue<>(SNAPSHOT_COMPARATOR);
  }

  @Override
  public void run() throws Exception {
    FileStatus[] fileStatuses = fs.listStatus(path, PATH_FILTER);
    boolean allStoresSnapshotsAreFresh = true;
    /**
     * For each store_version, we do the checks for snapshots freshness.
     */
    for (FileStatus fileStatus : fileStatuses) {
      /**
       * The queue is reused for all stores. Clear the snapshot queue when starting dealing with each store version.
       */
      snapshotQueue.clear();
      if (!fileStatus.isDirectory()) {
        logger.info("Skipping " + fileStatus.getPath().getName());
        continue;
      }
      String storeVersion = fileStatus.getPath().getName();
      FileStatus[] snapshotStatuses = fs.listStatus(fileStatus.getPath(), PATH_FILTER);
      for (FileStatus snapshotStatus : snapshotStatuses) {
        if (!snapshotStatus.isDirectory()) {
          logger.info("Skipping " + snapshotStatus.toString() + " because it's not a snapshot directory");
          continue;
        }
        snapshotQueue.add(snapshotStatus);
      }

      /**
       * Check if today's snapshots have been published, unified to use PT time
       */
      Date todaysDate = convertFromUTCtoPT(new Date(System.currentTimeMillis()));
      Long latestSnapshotRecordsNum = getRecordsNumforSnapshots(todaysDate);
      logger.info("The summary for " + storeVersion + " :");
      if (latestSnapshotRecordsNum == null) {
        allStoresSnapshotsAreFresh = false;
        logger.warn("Today's records number: Not published");
        continue;
      } else {
        logger.info("Today's records number: " + latestSnapshotRecordsNum);
      }

      /**
       * Pops all snapshots whose modification date is after yesterday
       */
      Date yesterdaysDate = DateUtils.addDays(todaysDate, -1);
      removeSnapshotsLaterThanYesterday(yesterdaysDate);

      /**
       * Check if yesterday's snapshots have been published and output the number of records increased since yesterday
       */
      Long lastSnapshotRecordsNum = getRecordsNumforSnapshots(yesterdaysDate);
      if (lastSnapshotRecordsNum == null) {
        logger.warn("Yesterday's records number: Not published");
        continue;
      } else {
        logger.info("Yesterday's records number: " + lastSnapshotRecordsNum);
      }
      Long increasedRecordsNum = latestSnapshotRecordsNum - lastSnapshotRecordsNum;
      if (increasedRecordsNum <= 0) {
        allStoresSnapshotsAreFresh = false;
      }
      logger.info("Today's records number has increased by " + increasedRecordsNum + " since yesterday.\n");
    }
    if (!allStoresSnapshotsAreFresh) {
      throw new VeniceException("Freshness check fails. At least one of stores doesn't have snapshots today "
          + "or today's records number doesn't increase compared to yesterday. Please check the summaries.");
    }
  }

  /**
   * It pops the latest element from snapshotQueue if the queue is not empty, and then check whether
   * the element's modification time is same day as the parameter date. If it's the same day, then it
   * parses the element title to get the records number.
   * @param dateToCompare
   * @return the number of records for latest snapshot in the priority queue.
   */
  private Long getRecordsNumforSnapshots(Date dateToCompare) {
    Long recordsNum = null;
    if (!snapshotQueue.isEmpty()) {
      FileStatus snapshotStatus = snapshotQueue.poll();
      /**
       * The default time zone returned by Azkaban is in PT.
       */
      Date modificationDate = new Date(snapshotStatus.getModificationTime());
      if (DateUtils.isSameDay(modificationDate, dateToCompare)) {
        String snapshotName = snapshotStatus.getPath().getName();
        Matcher m = SNAPSHOT_PATTERN.matcher(snapshotName);
        if (m.matches()) {
          /**
           * Gets the records number from path name parsing.
           * The snapshot name is composed as (timestamp)(SNAPSHOT_SEPARATOR)(recordsNum).
           */
          recordsNum = Long.parseLong(snapshotName.split(SNAPSHOT_SEPARATOR)[1]);
        }
      }
    }
    return recordsNum;
  }

  /**
   * Remove all snapshots which comes later than yesterday, i.e. all today's
   * snapshots will be removed.
   */
  private void removeSnapshotsLaterThanYesterday(Date dateToCompare) {
    while (!snapshotQueue.isEmpty()) {
      FileStatus snapshotStatus = snapshotQueue.peek();
      Date modificationDate = new Date(snapshotStatus.getModificationTime());
      /**
       * The snapshot queue is sorted from late to early time for snapshot modification time.
       * We keep removing the snapshot until seeing a snapshot published yesterday.
       */
      if (!DateUtils.isSameDay(modificationDate, dateToCompare)) {
        snapshotQueue.poll();
      } else {
        return;
      }
    }
  }

  /**
   * Convert a UTC date to PT. UTC is 8 hours ahead of Pacific Time.
   * @param date
   * @return
   */
  private Date convertFromUTCtoPT(Date date) {
    return DateUtils.addHours(date, -8);
  }

  /**
   * ignore hdfs files with prefix "_" and "."
   */
  private static final PathFilter PATH_FILTER = p -> !p.getName().startsWith("_") && !p.getName().startsWith(".");
}
