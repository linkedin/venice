// The start parameters below enable parallelization of many independent modules.
// We can't enable it by default because it breaks buildAll. We can still use
// parallel execution by doing: `./gradlew clean build --parallel`
// gradle.startParameter.setParallelProjectExecutionEnabled(true)
// gradle.startParameter.setMaxWorkerCount(10)

if (project.hasProperty('overrideBuildEnvironment')) {
  if(project.overrideBuildEnvironment) {
    apply from: file(project.overrideBuildEnvironment)
    product {
      codeQuality {
        ignoreFailures = true
      }
    }
  }
}

apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'eclipse'

// Internal LinkedIn Kafka release
def internalKafkaGroup = "kafka"
def internalKafkaVersion = "0.11.1.3"

// OSS Kafka release (currently not used)
def ossKafkaGroup = "org.apache.kafka"
def ossKafkaVersion = "0.10.1.1"
def ddsStorageCoreVersion = "5.1.10"

ext.libraries = [ // Groovy map literal
                  avro: 'org.apache.avro:avro:1.7.7',
                  avroMapred: 'org.apache.avro:avro-mapred:1.7.7',
                  avroMigrationHelper: 'com.linkedin.avro-schemas:avro-migration-helper:45.0.35',
                  azkaban: 'com.linkedin.azkaban:azkaban:2.5.0',
                  bdbJe: 'com.sleepycat:je:5.0.104',
                  //brooklin: 'com.github.datastream:brooklin-samza:3.0.8',
                  brooklinCommon: 'com.linkedin.brooklin-li-common:brooklin-li-common:14.0.7',
                  brooklinKafka: 'com.github.datastream:datastream-kafka-connector:6.0.38',
                  brooklinKafkaTransport: 'com.github.datastream:datastream-kafka:6.0.38',
                  brooklinTest: 'com.linkedin.brooklin-li-common:brooklin-test-pub:14.0.7',
                  bouncyCastle: 'org.bouncycastle:bcprov-jdk15on:1.55',
                  commonsCodec: 'commons-codec:commons-codec:1.4',
                  commonsIo: 'commons-io:commons-io:2.4',
                  //TODO: remove guava library dependency since it could cause a lot of indirect dependency conflicts.
                  guava: 'com.google.guava:guava:18.0',
                  helix: 'org.apache.helix:helix-core:0.8.2.6',
                  kafka: internalKafkaGroup + ':kafka_2.10:' + internalKafkaVersion,
                  kafkaTest: internalKafkaGroup + ':kafka_2.10:' + internalKafkaVersion+":test",
                  kafkaClients: internalKafkaGroup + ':kafka-clients:' + internalKafkaVersion,
                  kafkaClientsTest: internalKafkaGroup + ':kafka-clients:' + internalKafkaVersion+":test",
                  // kafka: ossKafkaGroup + ':kafka_2.10:' + ossKafkaVersion,
                  // kafkaClients: ossKafkaGroup + ':kafka-clients:' + ossKafkaVersion,
                  mockito: 'org.mockito:mockito-core:2.18.3',
                  netty: 'io.netty:netty-all:4.1.6.Final',
                  zkclient: 'com.101tec:zkclient:0.7', //for Kafka AdminUtils
                  d2: 'com.linkedin.container:pegasus-d2-server-factory:25.2.15',
                  d2Client: 'com.linkedin.container:pegasus-d2-client-factory:25.2.15',
                  routerApi: 'com.linkedin.dds-storage-core:dds-storage-router-api:' + ddsStorageCoreVersion,
                  routerImpl: 'com.linkedin.dds-storage-core:dds-storage-router-impl:' + ddsStorageCoreVersion,
                  routerNetty4: 'com.linkedin.dds-storage-core:dds-storage-netty4-base:' + ddsStorageCoreVersion,
                  routerLnkd: 'com.linkedin.dds-storage-core:dds-storage-router-lnkd:' + ddsStorageCoreVersion,
                  netty4Lnkd: 'com.linkedin.dds-storage-core:dds-storage-netty4-lnkd:' + ddsStorageCoreVersion,
                  oss: 'org.sonatype.oss:oss-parent:7',
                  asyncHttpClient: 'org.apache.httpcomponents:httpasyncclient:4.1.2',
                  zookeeper: 'org.apache.zookeeper:zookeeper:3.4.6',

                  // Gibblin dependencies
                  gobblinCoreBase: 'com.linkedin.gobblin:gobblin-core-base:0.11.0',
                  gobblinKafkaJobConstructs: 'com.linkedin.gobblin-kafka:job-constructs:2.0.7',
                  gobblinKafkaCommon: 'com.linkedin.gobblin-proxy:gobblin-kafka-common:1.64.96',

                  // Hadoop to Venice Bridge dependencies
                  mapreduceClientCore: 'org.apache.hadoop:hadoop-mapreduce-client-core:2.3.0',
                  commonsConfiguration: 'commons-configuration:commons-configuration:1.9',
                  commonsLang: 'commons-lang:commons-lang:2.6',
                  hadoopCommon: 'org.apache.hadoop:hadoop-common:2.3.0',
                  httpClient: 'org.apache.httpcomponents:httpclient:4.5.2',
                  httpCore: 'org.apache.httpcomponents:httpcore:4.4.5',
                  jacksonCore: 'org.codehaus.jackson:jackson-core-asl:1.9.6',
                  jacksonMapper: 'org.codehaus.jackson:jackson-mapper-asl:1.9.6',
                  jdom: 'org.jdom:jdom:1.1',
                  joptSimple: 'net.sf.jopt-simple:jopt-simple:3.2',
                  log4j: 'log4j:log4j:1.2.17',
                  snappy: 'org.xerial.snappy:snappy-java:1.0.4.1',
                  testng: 'org.testng:testng:6.14.3',
                  // TODO remove this linkedin MP dependency, instead depends on the opensource tehuti lib.
                  tehuti: 'com.linkedin.tehuti:tehuti:0.7.1.6',
                  // Resolves java.lang.UnsupportedOperationException:  setXIncludeAware is not supported on this JAXP implementation or earlier: class org.apache.xerces.jaxp.DocumentBuilderFactoryImpl
                  xalan: 'xalan:xalan:2.7.1',
                  xerces: 'xerces:xercesImpl:2.9.1',

                  // Hadoop to Venice Bridge test dependencies
                  mapreduceClientJobClient: 'org.apache.hadoop:hadoop-mapreduce-client-jobclient:2.3.0',

                  // Samza dependencies
                  samzaApi: 'com.linkedin.samza-li:samza-api:207.13.2.31', //equivalent to org.apache.samza 0.13

                  // off-heap cache
                  ohcCoreJ8: 'org.caffinitas.ohc:ohc-core-j8:0.6.1',

                  // Added during dds-storage-core v2 => v3
                  // Transitive dependency, to replace implicit version 11.0.17 which caused 4 test cases to fail:
                  // 1. TestAdminSparkServer.controllerClientCanDeleteStore
                  // 2. TestAdminSparkServer.controllerClientCanDeleteOldVersion
                  // 3. TestAdminSparkServer.controllerClientCanDeleteAllVersion
                  // 4. TestBrooklin.canReplicateKafkaWithBrooklinTopicReplicator
                  restliDocgen: 'com.linkedin.pegasus:restli-docgen:15.1.10',

                  // RocksDB
                  rocksdbjni: 'org.rocksdb:rocksdbjni:5.14.2'
]

subprojects {
  apply plugin: 'java'
  apply plugin: 'idea'
  apply plugin: 'eclipse'
  apply plugin: 'jacoco'

  sourceCompatibility = 1.8
  if (!project.hasProperty('overrideBuildEnvironment') ||
     !project.overrideBuildEnvironment) {
     version = '0.1'
  }
  repositories {
    ivy {  //TODO: remove this before opensourcing
      url 'http://artifactory.corp.linkedin.com:8081/artifactory/release/'
      layout "pattern", {
        ivy '[organisation]/[module]/[revision]/[module]-[revision].ivy'
        artifact '[organisation]/[module]/[revision]/[artifact]-[revision](-[classifier]).[ext]'
        m2compatible = true
      }
    }
    mavenCentral() // when build fails, move this to first and then build, then move it back and build should work
    maven {
      url "http://download.oracle.com/maven/"
    }
  }

  dependencies {
    compile 'org.slf4j:slf4j-log4j12:1.7.14'
    compile 'javax.validation:validation-api:1.0.0.GA'

    testCompile libraries.testng
    testCompile libraries.mockito
    // Test utils and framework for all unit tests and integration tests.
    testCompile project(':venice-test-common_2.10')
  }

  idea {
    module {
      downloadJavadoc = true
      downloadSources = true
    }
  }

  test {
    useTestNG()

    // Tests should run in parallel (this controls the number of parallel tests within a single module)
    maxParallelForks = 2
    forkEvery = 10

    testLogging {
      events "started", "failed", "passed", "skipped"
      showStandardStreams = false // to mute the DDS Router's noisy behavior...
      exceptionFormat = 'full'
    }
  }

  jacoco {
    toolVersion = "0.7.6.201602180812"
  }

  jacocoTestReport {
    dependsOn test
    reports {
      xml.enabled false
      csv.enabled false
      html.destination "${buildDir}/jacocoHtml"
    }
  }

  build.dependsOn jacocoTestReport
}

task unitTests {
  dependsOn 'venice-common_2.10:build'
  dependsOn 'venice-thin-client:build'
  dependsOn 'venice-server:build'
  dependsOn 'venice-controller:build'
  dependsOn 'venice-router:build'
  dependsOn 'hadoop-to-venice-bridge:build'
  dependsOn 'venice-schema-common:build'

  dependsOn 'venice-common_2.10:buildJar'
  dependsOn 'venice-server:installDist'
  dependsOn 'venice-controller:installDist'
  dependsOn 'venice-router:installDist'
  // dependsOn 'hadoop-to-venice-bridge:installApp'
  dependsOn 'venice-admin-tool:build'
  dependsOn 'venice-test-common_2.10:build'
  dependsOn 'venice-samza:build'

  dependsOn 'venice-etl:build'
}

task integrationTests {
  dependsOn 'venice-test-common_2.10:integrationtest'
}

task integrationtest {
  // just a rename to the new syntax, while maintaining backwards compat
  dependsOn integrationTests
}

task buildAll {
  dependsOn unitTests
  dependsOn integrationTests
}

task wrapper(type: Wrapper) {
  gradleVersion = '2.14'
}
