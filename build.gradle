import com.github.spotbugs.snom.SpotBugsTask
import org.gradle.internal.logging.text.StyledTextOutput.Style
import org.gradle.internal.logging.text.StyledTextOutputFactory

import java.nio.file.Files

plugins {
  id 'idea'
  id 'java'
  id 'maven-publish'
  id 'com.diffplug.spotless' version '6.12.0'
  id 'com.dorongold.task-tree' version '2.1.0'
  id 'com.github.johnrengelman.shadow' version '7.1.2' apply false
  id 'com.github.spotbugs' version '4.8.0' apply false
  id 'org.gradle.test-retry' version '1.6.0' apply false
  id 'com.form.diff-coverage' version '0.9.5' apply false
  id 'me.champeau.jmh' version '0.6.7' apply false
  id 'io.github.lhotari.gradle-nar-plugin' version '0.5.1' apply false
  id 'com.google.protobuf' version '0.9.3' apply false
  id 'org.checkerframework' version '0.6.47' // Checker Framework pluggable type-checking
}

apply from: "$rootDir/gradle/helper/git.gradle"
apply from: "$rootDir/gradle/helper/publishing.gradle"

/*
 * This snippet allows the Gradle environment to be overridden with custom
 * settings. This is useful in environments (such as a private company) where a
 * third party wishes to use custom repositories, or inject certain
 * functionality into the default Gradle build lifecycle.
 */
if (project.hasProperty('overrideBuildEnvironment')) {
  apply from: file(project.overrideBuildEnvironment)
  product {
    codeQuality {
      ignoreFailures = true
    }
  }
}

def avroVersion = '1.10.2'
def avroUtilVersion = '0.4.22'
def grpcVersion = '1.49.2'
// N.B.: The build should also work when substituting Kafka from the Apache fork to LinkedIn's fork:
def kafkaGroup = 'org.apache.kafka' // 'com.linkedin.kafka'
def kafkaVersion = '2.4.1' // '2.4.1.65'
def log4j2Version = '2.17.1'
def pegasusVersion = '29.31.0'
def protobufVersion = '3.21.7'
def jacksonVersion = '2.13.4'
def pulsarGroup = 'org.apache.pulsar'
def pulsarVersion = '2.10.3'
def alpnAgentVersion = '2.0.10'
def hadoopVersion = '2.10.2'
def apacheSparkVersion = '3.3.3'
def antlrVersion = '4.8'
def scala = '2.12'
def openTelemetryVersion = '1.33.0'

ext.libraries = [
    alpnAgent: "org.mortbay.jetty.alpn:jetty-alpn-agent:${alpnAgentVersion}",
    antlr4: "org.antlr:antlr4:${antlrVersion}",
    antlr4Runtime: "org.antlr:antlr4-runtime:${antlrVersion}",
    apacheSparkAvro: "org.apache.spark:spark-avro_${scala}:${apacheSparkVersion}",
    apacheSparkCore: "org.apache.spark:spark-core_${scala}:${apacheSparkVersion}",
    apacheSparkSql: "org.apache.spark:spark-sql_${scala}:${apacheSparkVersion}",
    avro: "org.apache.avro:avro:${avroVersion}",
    avroCompiler: "org.apache.avro:avro-compiler:${avroVersion}",
    avroMapred: "org.apache.avro:avro-mapred:${avroVersion}",
    avroUtilBuilder: "com.linkedin.avroutil1:builder:${avroUtilVersion}",
    avroUtilCompatHelper: "com.linkedin.avroutil1:helper-all:${avroUtilVersion}",
    avroUtilFastserde: "com.linkedin.avroutil1:avro-fastserde:${avroUtilVersion}",
    avroUtilSpotbugsPlugin: 'com.linkedin.avroutil1:spotbugs-plugin:0.2.69',
    bouncyCastle: 'org.bouncycastle:bcprov-jdk15on:1.55',
    bouncyCastleBcpkix: 'org.bouncycastle:bcpkix-jdk15on:1.55',
    caffeine: 'com.github.ben-manes.caffeine:caffeine:2.8.5',
    classgraph: 'io.github.classgraph:classgraph:4.8.60',
    commonsCodec: 'commons-codec:commons-codec:1.4',
    commonsConfiguration: 'commons-configuration:commons-configuration:1.9',
    commonsIo: 'commons-io:commons-io:2.11.0',
    commonsCli: 'commons-cli:commons-cli:1.5.0',
    commonsLang: 'commons-lang:commons-lang:2.6',
    conscrypt: 'org.conscrypt:conscrypt-openjdk-uber:2.5.2',
    d2: "com.linkedin.pegasus:d2:${pegasusVersion}",
    duckdbJdbc: "org.duckdb:duckdb_jdbc:1.2.0-20250121.012246-127", // TODO: Remove SNAPSHOT when the real release is published!
    failsafe: 'net.jodah:failsafe:2.4.0',
    fastUtil: 'it.unimi.dsi:fastutil:8.3.0',
    grpcNettyShaded: "io.grpc:grpc-netty-shaded:${grpcVersion}",
    grpcProtobuf: "io.grpc:grpc-protobuf:${grpcVersion}",
    grpcServices: "io.grpc:grpc-services:${grpcVersion}",
    grpcStub: "io.grpc:grpc-stub:${grpcVersion}",
    grpcTesting: "io.grpc:grpc-testing:${grpcVersion}",
    hadoopCommon: "org.apache.hadoop:hadoop-common:${hadoopVersion}",
    hadoopHdfs: "org.apache.hadoop:hadoop-hdfs:${hadoopVersion}",
    httpAsyncClient: 'org.apache.httpcomponents:httpasyncclient:4.1.5',
    httpClient5: 'org.apache.httpcomponents.client5:httpclient5:5.3',
    httpCore5: 'org.apache.httpcomponents.core5:httpcore5:5.2.4',
    httpCore5H2: 'org.apache.httpcomponents.core5:httpcore5-h2:5.2.4',
    httpClient: 'org.apache.httpcomponents:httpclient:4.5.14',
    httpCore: 'org.apache.httpcomponents:httpcore:4.4.16',
    jacksonCore: "com.fasterxml.jackson.core:jackson-core:${jacksonVersion}",
    jacksonAnnotations: "com.fasterxml.jackson.core:jackson-annotations:${jacksonVersion}",
    jacksonDatabind: "com.fasterxml.jackson.core:jackson-databind:${jacksonVersion}",
    javax: 'javax.servlet:javax.servlet-api:3.1.0',
    javaxActivation: 'com.sun.activation:javax.activation:1.2.0',
    jdom: 'org.jdom:jdom:1.1',
    jna: 'net.java.dev.jna:jna:4.5.1',
    jsr305: 'com.google.code.findbugs:jsr305:3.0.2',
    joptSimple: 'net.sf.jopt-simple:jopt-simple:3.2',
    kafka: "${kafkaGroup}:kafka_${scala}:${kafkaVersion}",
    kafkaClients: "${kafkaGroup}:kafka-clients:${kafkaVersion}",
    kafkaClientsTest: "${kafkaGroup}:kafka-clients:${kafkaVersion}:test",
    log4j2api: "org.apache.logging.log4j:log4j-api:${log4j2Version}",
    log4j2core: "org.apache.logging.log4j:log4j-core:${log4j2Version}",
    log4j2Slf4j: "org.apache.logging.log4j:log4j-slf4j-impl:${log4j2Version}",
    mail: 'javax.mail:mail:1.4.4',
    mapreduceClientCore: "org.apache.hadoop:hadoop-mapreduce-client-core:${hadoopVersion}",
    mapreduceClientJobClient: "org.apache.hadoop:hadoop-mapreduce-client-jobclient:${hadoopVersion}",
    mockito: 'org.mockito:mockito-core:4.11.0',
    netty: 'io.netty:netty-all:4.1.74.Final',
    opentelemetryApi: "io.opentelemetry:opentelemetry-api:${openTelemetryVersion}",
    opentelemetrySdk: "io.opentelemetry:opentelemetry-sdk:${openTelemetryVersion}",
    opentelemetryExporterLogging: "io.opentelemetry:opentelemetry-exporter-logging:${openTelemetryVersion}",
    opentelemetryExporterOtlp: "io.opentelemetry:opentelemetry-exporter-otlp:${openTelemetryVersion}",
    opentelemetryExporterCommon: "io.opentelemetry:opentelemetry-exporter-common:${openTelemetryVersion}",
    oss: 'org.sonatype.oss:oss-parent:7',
    pulsarClient: "${pulsarGroup}:pulsar-client:${pulsarVersion}",
    pulsarIoCore: "${pulsarGroup}:pulsar-io-core:${pulsarVersion}",
    pulsarIoCommon: "${pulsarGroup}:pulsar-io-common:${pulsarVersion}",
    r2: "com.linkedin.pegasus:r2:${pegasusVersion}",
    restliCommon: "com.linkedin.pegasus:restli-common:${pegasusVersion}",
    rocksdbjni: 'org.rocksdb:rocksdbjni:8.8.1',
    samzaApi: 'org.apache.samza:samza-api:1.5.1',
    beamSdk: 'org.apache.beam:beam-sdks-java-core:2.60.0',
    beamExtensionAvro: 'org.apache.beam:beam-sdks-java-extensions-avro:2.60.0',
    slf4j: 'org.slf4j:slf4j:1.7.36',
    slf4jApi: 'org.slf4j:slf4j-api:1.7.36',
    slf4jSimple: 'org.slf4j:slf4j-simple:1.7.36',
    snappy: 'org.iq80.snappy:snappy:0.4',
    spark: 'com.sparkjava:spark-core:2.9.4', // Spark-Java Rest framework
    spotbugs: 'com.github.spotbugs:spotbugs:4.5.2',
    tehuti: 'io.tehuti:tehuti:0.12.3',
    testcontainers: 'org.testcontainers:testcontainers:1.18.0',
    testng: 'org.testng:testng:6.14.3',
    tomcatAnnotations: 'org.apache.tomcat:annotations-api:6.0.53',
    // Resolves java.lang.UnsupportedOperationException:  setXIncludeAware is not supported on this JAXP implementation
    // or earlier: class org.apache.xerces.jaxp.DocumentBuilderFactoryImpl
    xalan: 'xalan:xalan:2.7.1',
    xerces: 'xerces:xercesImpl:2.9.1',
    zkclient: 'com.101tec:zkclient:0.7', // For Kafka AdminUtils
    zookeeper: 'org.apache.zookeeper:zookeeper:3.6.3',
    zstd: 'com.github.luben:zstd-jni:1.5.2-3'
]

group = 'com.linkedin.venice'

publishing {
  repositories {
    mavenLocal()
    maven {
      name 'LinkedInJFrog'
      url 'https://linkedin.jfrog.io/artifactory/venice'
      if (System.getenv('JFROG_USERNAME') != null && System.getenv('JFROG_API_KEY') != null) {
        credentials {
          username System.getenv('JFROG_USERNAME')
          password System.getenv('JFROG_API_KEY')
        }
      }
    }
  }
}

def parser = new XmlSlurper()
parser.setFeature("http://apache.org/xml/features/disallow-doctype-decl", false)
parser.setFeature("http://apache.org/xml/features/nonvalidating/load-external-dtd", false)

configurations {
  alpnAgent {
  }
}

dependencies {
  alpnAgent libraries.alpnAgent
}

subprojects {
  //apply group and version to all submodules
  group = rootProject.group
  version = rootProject.version

  def isLeafSubModule = project.childProjects.isEmpty()

  // We consider a sub-module to be a "proto module" if it has any proto schemas defined under the right path.
  def protoDir = new File(project.projectDir, "src/main/proto");
  def isProtoModule = protoDir != null && protoDir.list() != null && protoDir.list().size() != 0

  apply {
    plugin 'idea'
    plugin 'java-library'
    plugin 'com.form.diff-coverage'
    plugin 'com.github.spotbugs'
    plugin 'org.gradle.test-retry'
    plugin 'org.checkerframework'
  }

  if (isLeafSubModule) {
    apply {
      plugin 'jacoco'
      if (isProtoModule) {
        plugin 'com.google.protobuf'
      }
    }
  }

  if (JavaVersion.current() >= JavaVersion.VERSION_1_9) {
    tasks.withType(JavaCompile) {
      // Compiler arguments can be injected here...
      // options.compilerArgs << '-Xlint:unchecked'
      options.release = 8
    }
  }

  java {
    withSourcesJar()
    // TODO: Enable after we have valid javadocs
    //withJavadocJar()
  }

  if (isLeafSubModule && isProtoModule) {
    protobuf {
      protoc {
        artifact = 'com.google.protobuf:protoc:' + protobufVersion
      }
      plugins {
        grpc {
          artifact = 'io.grpc:protoc-gen-grpc-java:' + grpcVersion
        }
      }
      generateProtoTasks {
        ofSourceSet('main')*.plugins {
          grpc {}
        }
      }
    }
  }

  configurations {
    implementation {
      // These are global exclusions that will apply to the entire project
      exclude group: 'backport-util-concurrent'
      exclude group: 'com.intellij.annotations'
      exclude group: 'com.linkedin.avro-schemas'
      exclude group: 'com.linkedin.container'
      exclude group: 'com.linkedin.container-core'
      exclude group: 'com.linkedin.security'
      exclude group: 'com.linkedin.dds-storage-core'
      exclude group: 'com.linkedin.linkedin-kafka-clients'
      exclude group: 'com.linkedin.util', module: 'util-sql'
      exclude group: 'org.slf4j', module: 'slf4j-log4j12'
      exclude module: 'clojure'
      exclude module: 'kafka_2.10' // This ends up getting pulled in by a few dependencies, unfortunately :/ ...
      exclude module: 'kafka_2.11'
    }
    compileOnly {
      // These dependencies are transitively used at runtime, so we cannot exclude them further than compileOnly
      exclude group: 'com.typesafe.scala-logging'
      exclude group: 'log4j'
      exclude group: 'org.slf4j'
    }
    all {
      resolutionStrategy.force libraries.zookeeper
    }
    avroCompiler {
    }
  }

  dependencies {
    testImplementation libraries.log4j2api
    testImplementation libraries.mockito
    testImplementation libraries.testng
    // Test utils and framework for all unit tests and integration tests.
    testImplementation project(':internal:venice-test-common')

    spotbugs libraries.spotbugs
    spotbugsPlugins libraries.avroUtilSpotbugsPlugin

    avroCompiler libraries.avroCompiler
    avroCompiler libraries.avroUtilBuilder
    avroCompiler 'org.slf4j:slf4j-simple:1.7.32'
    implementation libraries.grpcNettyShaded
    implementation libraries.grpcProtobuf
    implementation libraries.grpcServices
    implementation libraries.grpcStub
    implementation 'org.ow2.asm:asm:9.7'
    compileOnly libraries.tomcatAnnotations
  }

  idea {
    module {
      downloadJavadoc = true
      downloadSources = true
    }
  }

  task compileAvro(type: SourceTask) {
    def sourceDir = file('src/main/resources/avro')
    def outputDir = file("$buildDir/generated/sources/avro/java/main")

    source sourceDir
    inputs.files(configurations.avroCompiler).withNormalizer(ClasspathNormalizer)
    outputs.dir(outputDir)
    outputs.cacheIf { true }

    doFirst {
      def versionOverrides = [
//        project(':internal:venice-common').file('src/main/resources/avro/StoreVersionState/v5', PathValidation.DIRECTORY)
      ]

      def schemaDirs = [sourceDir]
      sourceDir.eachDir { typeDir ->
        def parseVersionId = { dir ->
          (dir in versionOverrides) ? Integer.MAX_VALUE : dir?.name?.substring(1)?.toInteger()
        }
        def latestVersionDir = null
        typeDir.eachDirMatch(~/v-?\d+/) { versionDir ->
          if (parseVersionId(versionDir) > parseVersionId(latestVersionDir)) {
            latestVersionDir = versionDir
          }
        }
        if (latestVersionDir) {
          schemaDirs << latestVersionDir
        }
      }

      copy {
        from (schemaDirs) {
          include '*.avsc'
        }
        into temporaryDir
        duplicatesStrategy = DuplicatesStrategy.FAIL
        eachFile {
          println "Copying avro schema ${relativePath(it.file)} ${it.file.parentFile in versionOverrides ? '(OVERRIDE)' : ''}"
        }
      }

      javaexec {
        classpath = configurations.avroCompiler
        main = 'com.linkedin.avroutil1.builder.SchemaBuilder'
        args = [
            '--input', temporaryDir,
            '--output', outputDir
        ]
      }
    }
  }
  sourceSets.main.java.srcDir(compileAvro)

  tasks.withType(SpotBugsTask) {
    effort = 'max'
    reportLevel = 'low'
    includeFilter = file(
      project.hasProperty('spotallbugs') ?
        "$rootDir/gradle/spotbugs/include-all.xml" :
        "$rootDir/gradle/spotbugs/include.xml"
    )
    excludeFilter = file("$rootDir/gradle/spotbugs/exclude.xml")
    ignoreFailures = project.hasProperty('spotbugs.ignoreFailures')
    showStackTraces = false
    reports ({
      xml {
        enabled = project.hasProperty('spotbugs.xml')
      }
      html {
        enabled = !reports.getByName('XML').enabled
        stylesheet = 'fancy-hist.xsl'
      }
    })
    doFirst {
      sourceDirs += sourceSets.getByName(baseName).output.generatedSourcesDirs
      def generatedSources = sourceDirs.sum { dir ->
        dir.path =~ "^$buildDir/generated/sources/" ?
          fileTree(dir: dir, include: '**/*.java').collect { dir.relativePath(it) } : []
      }
      if (generatedSources) {
        def generatedClasses = generatedSources*.replaceFirst('.java$', '').sum {
          [ it + '.class', it + '\$*.class' ]
        }
        classes = classDirs.asFileTree.matching { exclude generatedClasses }
        auxClassPaths += classDirs.asFileTree.matching { include generatedClasses }.each {
          // Muted to reduce noise, but can be uncommented to debug exclusions
          // println "Excluding generated class ${project.relativePath(it)}"
        }
      }
    }
  }

  def ALPINI_TEST_FILTER = 'com.linkedin.alpini.*'
  def ALPINI_NETTY_TEST_FILTER = 'io.netty.*'
  def ALPINI_UNIT_TEST_TASK_NAME = 'alpiniUnitTest'

  tasks.withType(Test) {
    mustRunAfter tasks.withType(SpotBugsTask)

    // For Spark to run on Java 17
    jvmArgs "-XX:+IgnoreUnrecognizedVMOptions"
    jvmArgs "--add-opens=java.base/java.nio=ALL-UNNAMED"
    jvmArgs "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED"
    jvmArgs "--add-opens=java.base/java.lang=ALL-UNNAMED"
    jvmArgs "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED"
    jvmArgs "--add-opens=java.base/jdk.internal.misc=ALL-UNNAMED"

    if (JavaVersion.current() == JavaVersion.VERSION_11) {
      jvmArgs "-Dio.netty.tryReflectionSetAccessible=true"
    }

    forkEvery = Integer.valueOf(System.getProperty('forkEvery', '0'))
    maxParallelForks = Integer.valueOf(System.getProperty('maxParallelForks', '4'))
    minHeapSize = System.getProperty('minHeapSize', '1g')
    maxHeapSize = System.getProperty('maxHeapSize', '4g')

    systemProperty 'pubSubBrokerFactory', System.getProperty('pubSubBrokerFactory', "com.linkedin.venice.integration.utils.KafkaBrokerFactory")

    System.getProperty('jvmArgs')?.eachMatch(/(?:[^\s'"]+|'[^']*'|"[^"]*")+/) { jvmArgs it }

    doFirst {
      println "forkEvery=$forkEvery"
      println "maxParallelForks=$maxParallelForks"
      println "jvmArgs=$allJvmArgs"
    }

    if (name != ALPINI_UNIT_TEST_TASK_NAME) {
      filter {
        excludeTestsMatching ALPINI_TEST_FILTER
        excludeTestsMatching ALPINI_NETTY_TEST_FILTER
        failOnNoMatchingTests = false
      }
    }

    useTestNG {
      excludeGroups 'flaky'
      listeners = ['com.linkedin.venice.testng.VeniceSuiteListener', 'com.linkedin.venice.testng.VeniceTestListener']
    }

    retry {
      maxRetries = 4 // 5 attempts in total
      maxFailures = 100
      failOnPassedAfterRetry = false
    }

    testLogging {
      events = [] // N.B. we suppress all events as everything is taken care of in beforeTest and afterTest
      showStandardStreams = false // to mute the DDS Router's noisy behavior...
      exceptionFormat = 'full'
    }

    beforeTest { descriptor ->
      def out = services.get(StyledTextOutputFactory).create("an-ouput")

      out.style(Style.Normal).println("$descriptor.className > $descriptor.displayName STARTED")
    }

    afterTest { descriptor, result ->
      def totalTime = result.endTime - result.startTime
      def prettyTime = totalTime < 1000 ? "$totalTime ms" : "${totalTime / 1000} s"
      def out = services.get(StyledTextOutputFactory).create("an-ouput")

      def style = result.resultType == TestResult.ResultType.SUCCESS
        ? Style.Identifier
        : result.resultType == TestResult.ResultType.FAILURE
          ? Style.Failure
          : Style.Normal

      def status = result.resultType == TestResult.ResultType.SUCCESS
        ? 'PASSED '
        : result.resultType == TestResult.ResultType.FAILURE
          ? 'FAILED '
          : 'SKIPPED '

      out.style(Style.Normal).text("$descriptor.className > $descriptor.displayName ")
          .style(style).text(status)
          .style(Style.Normal).println("($prettyTime)")

      if (result.resultType == TestResult.ResultType.FAILURE) {
        def originalStacktrace = result.exception.getStackTrace()
        ArrayList<StackTraceElement> truncatedStackTrace = []
        for (int i = 0; i < originalStacktrace.length; i++) {
          def element = originalStacktrace[i]
          def className = element.getClassName()
          if (i > 1 && (className.startsWith('org.gradle') || className.startsWith('jdk.internal'))) {
            break
          }
          truncatedStackTrace[i] = element
        }
        def truncatedException = result.exception
        truncatedException.setStackTrace(truncatedStackTrace.toArray(new StackTraceElement[0]))
        out.text('    ').exception(truncatedException)
      }
    }
  }

  if (isLeafSubModule) {
    jacocoTestReport {
      dependsOn test // tests are required to run before generating the report

      reports {
        xml.enabled = true
        html.enabled = true
      }
    }

    afterEvaluate {
      jacocoTestCoverageVerification {
        dependsOn jacocoTestReport

        violationRules {
          rule {
            def threshold = project.ext.has('jacocoCoverageThreshold') ? project.ext.jacocoCoverageThreshold : 0.6

            limit {
              counter = 'BRANCH'
              value = 'COVEREDRATIO'
              minimum = threshold
            }
            // Ignore generate files
            afterEvaluate {
              classDirectories.setFrom(files(classDirectories.files.collect { fileTree(dir: it, exclude: [
                  '**/com/linkedin/venice/protocols/**',
              ])}))
            }
          }
        }
      }

      diffCoverageReport {
        diffSource.file = createDiffFile()

        // Report locates at <module_name>/build/reports/jacoco/diffCoverage/html/index.html
        reports {
          html = true
          xml = true
        }

        violationRules {
          minBranches = project.ext.has('diffCoverageThreshold') ? project.ext.diffCoverageThreshold : 0.45
          failOnViolation = true
        }
      }

      task logCoverage {
        doLast {
          parseJacocoXml("$buildDir/reports/jacoco/test/jacocoTestReport.xml")
          parseJacocoXml("$buildDir/reports/jacoco/diffCoverage/report.xml")
        }
      }

      diffCoverage.dependsOn jacocoTestReport
      diffCoverage.finalizedBy logCoverage
    }
  }

  task flakyTest(type: Test) {
    useTestNG {
      includeGroups 'flaky'
    }
  }

  task "$ALPINI_UNIT_TEST_TASK_NAME"(type: Test) {
    useTestNG() {
      includeGroups 'unit'
    }
    filter {
      includeTestsMatching ALPINI_TEST_FILTER
      includeTestsMatching ALPINI_NETTY_TEST_FILTER
      failOnNoMatchingTests = false
    }
  }

  tasks.withType(Jar) {
    zip64 = true
    duplicatesStrategy = DuplicatesStrategy.FAIL
    exclude('**/*.xml')
  }

  task testJar(type: Jar) {
    classifier 'tests'
    from sourceSets.test.output
  }

  // Only publish artifacts for projects that are at the leaf level
  if (isLeafSubModule) {
    publishing.configureArtifactPublishing(project, testJar)
  }
}

// 2nd round of subprojects configuration... the 1st round must be fully done for all submodules for this one to work.
subprojects {
  task recursiveDiffCoverage {
    dependsOn subprojects.diffCoverage
  }
}

task aggregateJavadoc(type: Javadoc) {
  source subprojects.collect { project ->
    project.sourceSets.main.allJava
  }
  classpath = files(subprojects.collect { project ->
    project.sourceSets.main.compileClasspath
  })
  // generate javadoc with no warnings
  getOptions().addStringOption('Xdoclint:none', '-quiet')
  destinationDir = new File(buildDir, 'javadoc')
}

spotless {
  ratchetFrom "${git.getUpstreamRemote()}/main"
  java {
    importOrder()
    removeUnusedImports()
    eclipse().configFile("$rootDir/gradle/spotless/eclipse-java-formatter.xml")
    target '**/*.java'
    targetExclude '**/generated/**'
  }
}

task setupWorkspace {
  println 'Setting up default git config'
  def gitConfig = [
      'core.hooksPath' : 'gradle/githooks',
      'blame.ignoreRevsFile' : '.git-blame-ignore-revs',
      'branch.autoSetupMerge' : 'true', // Only track remote branches
      'branch.autoSetupRebase' : 'always',
      'pull.rebase' : 'true',
  ]
  gitConfig.each(git.setConfig)
}

task spotbugs {
  dependsOn subprojects.tasks*.withType(SpotBugsTask)
}
check.dependsOn(spotbugs)

test {
  mustRunAfter spotbugs
  dependsOn subprojects.test
  afterTest { descriptor, result ->
    def totalTime = result.endTime - result.startTime
    println "Total time of $descriptor.name was $totalTime"
  }
}

assemble {
  dependsOn (
    setupWorkspace,
    testClasses,
    'internal:venice-test-common:jmhClasses',
    'internal:venice-test-common:integrationTestClasses'
  )
}

build {
  dependsOn (
    'services:venice-router:installDist',
    'services:venice-server:installDist',
    'services:venice-controller:installDist'
  )
}

idea.project.ipr {
  withXml { provider ->
    provider.node.component
            .find { it.@name == 'VcsDirectoryMappings' }
            .mapping.@vcs = 'Git'

    def inspectionProjectProfileManager = provider.node.component
        .find { it.@name == 'InspectionProjectProfileManager' }

    def danglingJavaDocInspectionProperties = [
      class: "DanglingJavadoc",
      enabled: "false",
      level: "WARNING",
      enabled_by_default: "false"
    ]

    if (inspectionProjectProfileManager == null) {
      inspectionProjectProfileManager = provider.node.appendNode(
        "component",
        [
          name: "InspectionProjectProfileManager"
        ]
      )

      def profile = inspectionProjectProfileManager.appendNode(
        "profile",
        [
          version: "1.0"
        ]
      )

      profile.appendNode(
        "option",
        [
          name: "myName",
          value: "Project Default"
        ]
      )

      profile.appendNode(
        "inspection_tool",
        danglingJavaDocInspectionProperties
      )

      inspectionProjectProfileManager.appendNode(
        "version",
        [
          value: "1.0"
        ]
      )
    } else {
      def danglingJavaDoc = inspectionProjectProfileManager.profile.inspection_tool
          .find { it.@class == 'DanglingJavadoc' }
      if (danglingJavaDoc == null) {
        inspectionProjectProfileManager.profile.get(0).appendNode(
          "inspection_tool",
          danglingJavaDocInspectionProperties
        )
      } else {
        danglingJavaDoc.@enabled = false
        danglingJavaDoc.@level = "WARNING"
        danglingJavaDoc.@enabled_by_default = false
      }
    }
  }
}

// Allow running diffCoverage against uncommitted files
// See https://github.com/form-com/diff-coverage-gradle/issues/73
ext.createDiffFile = { ->
  // Files that we don't plan to write unit tests for now. Will be worked in the future
  def exclusionFilter = [
      // Keep this sorted
      // da-vinci-client
      ':!clients/da-vinci-client/src/main/java/com/linkedin/davinci/DaVinciBackend.java',
      ':!clients/da-vinci-client/src/main/java/com/linkedin/davinci/ingestion/isolated/IsolatedIngestionServer.java',
      ':!clients/da-vinci-client/src/main/java/com/linkedin/davinci/stats/ingestion/heartbeat/HeartbeatStatReporter.java',

      // venice-client
      ':!clients/venice-client/src/main/java/com/linkedin/venice/fastclient/factory/ClientFactory.java',
      // unit test for gRPC Transport Client is not straightforward, adding to exclusion list for now
      ':!clients/venice-client/src/main/java/com/linkedin/venice/fastclient/transport/GrpcTransportClient.java',
      // unit test for deprecated DispatchingVsonStoreClient is not meaningful since most logic is in its parent class
      ':!clients/venice-client/src/main/java/com/linkedin/venice/fastclient/DispatchingVsonStoreClient.java',

      // venice-producer
      ':!clients/venice-producer/src/main/java/com/linkedin/venice/producer/online/OnlineProducerFactory.java',
      ':!clients/venice-producer/src/main/java/com/linkedin/venice/producer/online/ProducerTool.java',

      // venice-common
      ':!internal/venice-common/src/main/java/com/linkedin/venice/controllerapi/ControllerClient.java',
      ':!internal/venice-common/src/main/java/com/linkedin/venice/acl/handler/StoreAclHandler.java',

      // venice-test-common
      ':!internal/venice-test-common/*',

      // venice-controller
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceController.java',
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceControllerService.java',
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceHelixAdmin.java',
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceParentHelixAdmin.java',

      // venice-router
      ':!services/venice-router/src/main/java/com/linkedin/venice/router/RouterServer.java',
      ':!services/venice-router/src/main/java/com/linkedin/venice/router/streaming/VeniceChunkedResponse.java',
      ':!services/venice-router/src/main/java/com/linkedin/venice/router/api/VeniceDispatcher.java',

      // venice-server
      ':!services/venice-server/src/main/java/com/linkedin/venice/server/VeniceServer.java',
      ':!services/venice-server/src/main/java/com/linkedin/venice/listener/StatsHandler.java',

      // venice-standalone
      ':!services/venice-standalone/*', // exclude the entire standalone project

      // admin-tool
      ':!clients/venice-admin-tool/*',

      // Keep this last
      // Other files that have tests but are not executed in the regular unit test task
      ':!internal/alpini/*'
  ]
  def file = Files.createTempFile(URLEncoder.encode(project.name, 'UTF-8'), '.diff').toFile()
  def diffBase = "${git.getUpstreamRemote()}/main"
  def command = [
      'git', 'diff', "${diffBase}...", '--no-color', '--minimal', '--', '.'
  ]
  command.addAll(exclusionFilter)
  file.withOutputStream { out ->
    exec {
      commandLine command
      standardOutput = out
    }
  }

  return file
}

// for a given xml jacoco report, parse it and print out the branch coverage
ext.parseJacocoXml = { filePath ->
  println "Parsing Jacoco XML file at: ${filePath}"
  try {
    def jacocoReport = parser.parse(filePath).children()
    def branchCoverage = jacocoReport.find { it.name() == 'counter' && it.@type == 'BRANCH' }
    def branchCoverageRatio = branchCoverage.@covered.toDouble() / (branchCoverage.@missed.toDouble() + branchCoverage.@covered.toDouble())
    println "Branch coverage: ${(branchCoverageRatio * 100.0).round(2)}%"
  } catch (Exception e) {
    // failure to retrieve numbers should not fail the build
    project.logger.debug("Branch coverage: N/A. There's either no branch coverage or " +
        "the jacoco report is not generated.", e)
  }
}

allprojects {
  task printAllDependencies(type: DependencyReportTask) {}
}

def supportedJdkVersions = [JavaVersion.VERSION_1_8, JavaVersion.VERSION_11, JavaVersion.VERSION_17]

task verifyJdkVersion {
  def currentJdkVersion = JavaVersion.current()
  def isSupported = supportedJdkVersions.any {version -> currentJdkVersion.equals(version) }
  if (!isSupported) {
    throw new GradleException("Invalid JDK version: ${currentJdkVersion}.\n" + \
    "Supported versions: ${supportedJdkVersions.join(', ')}.\n" + \
    "Please set the JAVA_HOME environment variable to a supported version either locally or globally.")
  }
  println "JDK version ${currentJdkVersion} is valid."
}

gradle.taskGraph.whenReady {
  // Ensure the JDK version is verified before any other tasks
  verifyJdkVersion
}

task listSubprojects {
  doLast {
    println "Subprojects:"
    subprojects.each { subproject ->
      println "${subproject.name}"
    }
  }
}
