import org.apache.tools.ant.taskdefs.condition.Os

buildscript {
  dependencies {
    classpath 'com.gradle:gradle-enterprise-gradle-plugin:3.5.2'
    classpath 'gradle.plugin.com.dorongold.plugins:task-tree:1.5'
    classpath "com.github.spotbugs:spotbugs-gradle-plugin:4.7.1"
  }
}

plugins {
  id 'java'
  id 'idea'
  id 'org.gradle.test-retry' version '1.2.0'
}

try {
  apply plugin: 'com.gradle.build-scan'
  gradleEnterprise {
    server = System.getProperty('buildScanServer', 'Set systemProp.buildScanServer in ~/.gradle/gradle.properties')
    buildScan {
      def commitId = 'git rev-parse --verify HEAD'.execute().text.trim()
      value 'CommitId', commitId
    }
  }
} catch (Exception e) {
  println "$e"
}

try {
  apply plugin: 'com.dorongold.task-tree'
  taskTree {
    noRepeat = true
  }
} catch (Exception e) {
  println "$e"
}

if (project.hasProperty('overrideBuildEnvironment')) {
  if (project.overrideBuildEnvironment) {
    apply from: file(project.overrideBuildEnvironment)
    product {
      codeQuality {
        ignoreFailures = true
      }
    }
  }
}

// Internal LinkedIn Kafka release
def internalKafkaGroup = 'com.linkedin.kafka'
def internalKafkaVersion = '2.3.0.30'

def ddsStorageCoreVersion = '13.0.16'

ext.libraries = [
    avro: 'org.apache.avro:avro:1.7.7',
    avroMapred: 'org.apache.avro:avro-mapred:1.7.7',
    avroUtilCompatibilityHelper: 'com.linkedin.avroutil1:helper-all:0.2.57',
    avroUtilFastserde: 'com.linkedin.avroutil1:avro-fastserde:0.2.62',
    brooklinCommon: 'com.linkedin.brooklin-li-common:brooklin-li-common:80.0.2',
    brooklinKafka: 'com.github.datastream:datastream-kafka-connector:36.0.1',
    brooklinKafkaTransport: 'com.github.datastream:datastream-kafka:36.0.1',
    brooklinTest: 'com.linkedin.brooklin-li-common:brooklin-test-pub:80.0.2',
    bouncyCastle: 'org.bouncycastle:bcprov-jdk15on:1.55',
    caffeine: 'com.github.ben-manes.caffeine:caffeine:2.8.5',
    commonsCodec: 'commons-codec:commons-codec:1.4',
    commonsIo: 'commons-io:commons-io:2.4',
    helix: 'org.apache.helix:helix-core:1.0.1.24',
    kafka: internalKafkaGroup + ':kafka_2.11:' + internalKafkaVersion,
    kafkaClients: internalKafkaGroup + ':kafka-clients:' + internalKafkaVersion,
    kafkaClientsTest: internalKafkaGroup + ':kafka-clients:' + internalKafkaVersion + ':test',
    mockito: 'org.mockito:mockito-core:3.3.3',
    netty: 'io.netty:netty-all:4.1.42.Final',
    zkclient: 'com.101tec:zkclient:0.7', //for Kafka AdminUtils
    d2: 'com.linkedin.container:pegasus-d2-server-factory:30.1.265',
    d2Client: 'com.linkedin.container:pegasus-d2-client-factory:38.4.175',
    r2Client: 'com.linkedin.container:pegasus-r2-client-factory:38.4.175',
    r2: "com.linkedin.pegasus:r2:29.18.2",
    routerApi: 'com.linkedin.dds-storage-core:dds-storage-router-api:' + ddsStorageCoreVersion,
    routerImpl: 'com.linkedin.dds-storage-core:dds-storage-router-impl:' + ddsStorageCoreVersion,
    ddsNettyBase: 'com.linkedin.dds-storage-core:dds-storage-netty4-base:' + ddsStorageCoreVersion,
    routerLnkd: 'com.linkedin.dds-storage-core:dds-storage-router-lnkd:' + ddsStorageCoreVersion,
    netty4Lnkd: 'com.linkedin.dds-storage-core:dds-storage-netty4-lnkd:' + ddsStorageCoreVersion,
    ddsStorageCommonBase: 'com.linkedin.dds-storage-core:dds-storage-common-base:' + ddsStorageCoreVersion,
    oss: 'org.sonatype.oss:oss-parent:7',
    asyncHttpClient: 'org.apache.httpcomponents:httpasyncclient:4.1.2',
    scalaLogging: 'com.typesafe.scala-logging:scala-logging_2.11:3.9.0',
    zookeeper: 'org.apache.zookeeper:zookeeper:3.4.6',
    zstd: 'com.github.luben:zstd-jni:1.4.4-7',

    // Hadoop to Venice Bridge dependencies
    mapreduceClientCore: 'org.apache.hadoop:hadoop-mapreduce-client-core:2.3.0',
    commonsConfiguration: 'commons-configuration:commons-configuration:1.9',
    commonsLang: 'commons-lang:commons-lang:2.6',
    hadoopCommon: 'org.apache.hadoop:hadoop-common:2.3.0',
    httpClient: 'org.apache.httpcomponents:httpclient:4.5.2',
    httpCore: 'org.apache.httpcomponents:httpcore:4.4.5',
    jacksonCore: 'org.codehaus.jackson:jackson-core-asl:1.9.6',
    jacksonMapper: 'org.codehaus.jackson:jackson-mapper-asl:1.9.6',
    javax: 'javax.servlet:javax.servlet-api:3.1.0',
    jdom: 'org.jdom:jdom:1.1',
    joptSimple: 'net.sf.jopt-simple:jopt-simple:3.2',
    log4j: 'log4j:log4j:1.2.17',
    log4j2api: 'org.apache.logging.log4j:log4j-api:2.9.1',
    log4j2core: 'org.apache.logging.log4j:log4j-core:2.9.1',
    snappy: 'org.xerial.snappy:snappy-java:1.0.4.1',
    // TODO: move back to open source sparkjava once they fix Jetty SSL.
    // spark: 'com.sparkjava:spark-core:2.9.1',
    spark: 'com.linkedin.li-sparkjava:li-sparkjava-impl:0.0.2',
    testng: 'org.testng:testng:6.14.3',
    tehuti: 'io.tehuti:tehuti:0.8.8',
    // Resolves java.lang.UnsupportedOperationException:  setXIncludeAware is not supported on this JAXP implementation or earlier: class org.apache.xerces.jaxp.DocumentBuilderFactoryImpl
    xalan: 'xalan:xalan:2.7.1',
    xerces: 'xerces:xercesImpl:2.9.1',

    // Hadoop to Venice Bridge test dependencies
    mapreduceClientJobClient: 'org.apache.hadoop:hadoop-mapreduce-client-jobclient:2.3.0',

    // Samza dependencies
    samzaApi: 'com.linkedin.samza-li:samza-api:311.1050.0.66', //equivalent to Samza-1.5

    // Added during dds-storage-core v2 => v3
    // Transitive dependency, to replace implicit version 11.0.17 which caused 4 test cases to fail:
    // 1. TestAdminSparkServer.controllerClientCanDeleteStore
    // 2. TestAdminSparkServer.controllerClientCanDeleteOldVersion
    // 3. TestAdminSparkServer.controllerClientCanDeleteAllVersion
    // 4. TestBrooklin.canReplicateKafkaWithBrooklinTopicReplicator
    restliDocgen: 'com.linkedin.pegasus:restli-docgen:15.1.10',

    // RocksDB
    rocksdbjni: 'org.rocksdb:rocksdbjni:6.20.3',

    // Flatbuffers lib, currently for benchmark only
    flatbuffersJava: 'com.google.flatbuffers:flatbuffers-java:1.11.0',

    // open source conscrypt from google
    conscrypt: 'org.conscrypt:conscrypt-openjdk-uber:2.4.0',
    classgraph: 'io.github.classgraph:classgraph:4.8.60',

    jmhCore: 'org.openjdk.jmh:jmh-core:1.28',
    jmhGenerator: 'org.openjdk.jmh:jmh-generator-annprocess:1.28',
    failsafe: 'net.jodah:failsafe:2.4.0',

    spotbugs: 'com.github.spotbugs:spotbugs:4.2.3',
    spotbugsPlugins: 'com.linkedin.avroutil1:spotbugs-plugin:0.2.51'
]

subprojects {
  apply plugin: 'java-library'
  apply plugin: 'idea'
  apply plugin: 'jacoco'
  apply plugin: 'org.gradle.test-retry'

  sourceCompatibility = 1.8
  if (!project.hasProperty('overrideBuildEnvironment') || !project.overrideBuildEnvironment) {
     version = '0.1'
  }

  repositories {
    ivy {  //TODO: remove this before opensourcing
      url 'http://artifactory.corp.linkedin.com:8081/artifactory/release/'
      patternLayout {
        ivy '[organisation]/[module]/[revision]/[module]-[revision].ivy'
        artifact '[organisation]/[module]/[revision]/[artifact]-[revision](-[classifier]).[ext]'
        m2compatible = true
      }
    }
    mavenCentral() // when build fails, move this to first and then build, then move it back and build should work
    maven {
      url 'https://dl.bintray.com/linkedin/maven/'
    }
  }

  configurations {
    implementation {
      // These are global exclusions that will apply to the entire project
      exclude group: 'backport-util-concurrent'
      exclude group: 'com.intellij.annotations'
      exclude group: 'com.linkedin.avro-schemas'
      // exclude group: 'com.linkedin.container'
      exclude group: 'com.linkedin.container-core'
      exclude group: 'com.linkedin.linkedin-kafka-clients'
      exclude group: 'com.linkedin.util', module: 'util-sql'
      exclude module: 'kafka_2.10' // This ends up getting pulled in by a few dependencies, unfortunately :/ ...
      // exclude group: 'org.eclipse.jetty'
    }
    compileOnly {
      // These dependencies are transitively used at runtime, so we cannot exclude them further than compileOnly
      exclude group: 'com.google.guava', module: 'guava' // Used by Brooklin at runtime
    }
  }

  dependencies {
    implementation 'org.slf4j:slf4j-log4j12:1.7.14'
    implementation 'javax.validation:validation-api:1.0.0.GA'

    testImplementation libraries.testng
    testImplementation libraries.mockito
    // Test utils and framework for all unit tests and integration tests.
    testImplementation project(':venice-test-common')
  }

  idea {
    module {
      downloadJavadoc = true
      downloadSources = true
    }
  }

  tasks.withType(Test) {
    useTestNG() {
      excludeGroups 'flaky'
      Set<String> suiteListeners = ["com.linkedin.venice.testng.VeniceSuiteListener"]
      setListeners(suiteListeners)
    }

    // The ALPN version should match the JVM version
    String osName = System.getProperty("os.name").toLowerCase(Locale.ENGLISH);
    if (JavaVersion.current().compareTo(JavaVersion.VERSION_11) < 0) {
      if (Os.isFamily(Os.FAMILY_MAC)) {
        jvmArgs '-Xbootclasspath/p:/Library/Java/Boot/1_8_0_172/alpn-boot-8.1.12.v20180117.jar'
      } else if (Os.isFamily(Os.FAMILY_UNIX)) {
        jvmArgs '-Xbootclasspath/p:/export/apps/jdkboot/1_8_0_172/alpn-boot-8.1.12.v20180117.jar'
      } else {
        throw new GradleException(osName + " is not supported since alpn only works for either Mac or Linux right now.")
      }
    }
    retry {
      maxRetries = 4 // 5 attempts in total
      maxFailures = 100
      failOnPassedAfterRetry = false
    }

    forkEvery = Integer.valueOf(System.getProperty('forkEvery', '0'))
    maxParallelForks = Integer.valueOf(System.getProperty('maxParallelForks', '4'))
    minHeapSize = System.getProperty('minHeapSize', '1g')
    maxHeapSize = System.getProperty('maxHeapSize', '4g')

    doFirst {
      println "forkEvery=$forkEvery"
      println "maxParallelForks=$maxParallelForks"
      println "minHeapSize=$minHeapSize"
      println "maxHeapSize=$maxHeapSize"
    }

    testLogging {
      events 'started', 'passed', 'failed', 'skipped'
      showStandardStreams = false // to mute the DDS Router's noisy behavior...
      exceptionFormat = 'full'
    }
  }

  task flakyTests(type: Test) {
    useTestNG() {
      includeGroups 'flaky'
    }
    mustRunAfter test
  }
}

// For now, only enable spotbugs in 'venice-thin-client' and 'da-vinci-client' since they are customer facing and so far
// only avro rules are enabled, and in the future, we would like to apply spotbugs to every module and include more rules.
allprojects.findAll { it.name in ['venice-thin-client', 'da-vinci-client'] }.each { p ->
  configure(p) {
    apply plugin: 'com.github.spotbugs'

    dependencies {
      spotbugs libraries.spotbugs

      //register spotbugs plugin(s)
      spotbugsPlugins libraries.spotbugsPlugins
    }

    spotbugs {
      //see https://spotbugs-gradle-plugin.netlify.app/com/github/spotbugs/snom/spotbugsextension for docs
      toolVersion = '4.2.3'
      includeFilter = file("../findbugs-include.xml")
      ignoreFailures = false
      showProgress = true
    }

    spotbugsMain {
      reports {
        html {
          enabled = true
          destination = file("$buildDir/reports/spotbugs/main/spotbugs.html")
          stylesheet = 'fancy-hist.xsl'
        }
      }
    }
  }
}

task unitTests {
  dependsOn subprojects.check
}

task flakyTests {
  dependsOn subprojects.flakyTests
  dependsOn 'venice-test-common:flakyIntegrationTests'
}

task integrationTests {
  dependsOn 'venice-test-common:integrationTests'
}

task buildAll {
  dependsOn unitTests
  dependsOn integrationTests
  dependsOn 'venice-common:buildJar'
  dependsOn 'venice-router:installDist'
  dependsOn 'venice-server:installDist'
  dependsOn 'venice-controller:installDist'
}

task compile {
  dependsOn compileJava
  dependsOn compileTestJava
  dependsOn 'venice-test-common:compileIntegrationTestJava'
}
