buildscript {
  dependencies {
    classpath 'com.gradle:gradle-enterprise-gradle-plugin:3.5.2'
    classpath 'gradle.plugin.com.dorongold.plugins:task-tree:1.5'
  }
}

plugins {
  id 'java'
  id 'idea'
  id 'org.gradle.test-retry' version '1.2.0'
}

try {
  apply plugin: 'com.gradle.build-scan'
  gradleEnterprise {
    server = System.getProperty('buildScanServer', 'Set systemProp.buildScanServer in ~/.gradle/gradle.properties')
    buildScan {
      def commitId = 'git rev-parse --verify HEAD'.execute().text.trim()
      value 'CommitId', commitId
    }
  }
} catch (Exception e) {
  println "$e"
}

try {
  apply plugin: 'com.dorongold.task-tree'
  taskTree {
    noRepeat = true
  }
} catch (Exception e) {
  println "$e"
}

if (project.hasProperty('overrideBuildEnvironment')) {
  if (project.overrideBuildEnvironment) {
    apply from: file(project.overrideBuildEnvironment)
    product {
      codeQuality {
        ignoreFailures = true
      }
    }
  }
}

// Internal LinkedIn Kafka release
def internalKafkaGroup = 'com.linkedin.kafka'
def internalKafkaVersion = '2.3.0.30'

def ddsStorageCoreVersion = '13.0.16'

ext.libraries = [
    avro: 'org.apache.avro:avro:1.7.7',
    avroMapred: 'org.apache.avro:avro-mapred:1.7.7',
    avroUtilCompatibilityHelper: 'com.linkedin.avroutil1:helper-all:0.2.30',
    avroUtilFastserde: 'com.linkedin.avroutil1:avro-fastserde:0.2.24',
    brooklinCommon: 'com.linkedin.brooklin-li-common:brooklin-li-common:80.0.2',
    brooklinKafka: 'com.github.datastream:datastream-kafka-connector:36.0.1',
    brooklinKafkaTransport: 'com.github.datastream:datastream-kafka:36.0.1',
    brooklinTest: 'com.linkedin.brooklin-li-common:brooklin-test-pub:80.0.2',
    bouncyCastle: 'org.bouncycastle:bcprov-jdk15on:1.55',
    caffeine: 'com.github.ben-manes.caffeine:caffeine:2.8.5',
    commonsCodec: 'commons-codec:commons-codec:1.4',
    commonsIo: 'commons-io:commons-io:2.4',
    helix: 'org.apache.helix:helix-core:1.0.1.24',
    kafka: internalKafkaGroup + ':kafka_2.11:' + internalKafkaVersion,
    kafkaClients: internalKafkaGroup + ':kafka-clients:' + internalKafkaVersion,
    kafkaClientsTest: internalKafkaGroup + ':kafka-clients:' + internalKafkaVersion + ':test',
    mockito: 'org.mockito:mockito-core:3.3.3',
    netty: 'io.netty:netty-all:4.1.22.Final',
    zkclient: 'com.101tec:zkclient:0.7', //for Kafka AdminUtils
    d2: 'com.linkedin.container:pegasus-d2-server-factory:30.1.265',
    d2Client: 'com.linkedin.container:pegasus-d2-client-factory:30.1.265',
    r2Client: 'com.linkedin.container:pegasus-r2-client-factory:30.1.269',
    routerApi: 'com.linkedin.dds-storage-core:dds-storage-router-api:' + ddsStorageCoreVersion,
    routerImpl: 'com.linkedin.dds-storage-core:dds-storage-router-impl:' + ddsStorageCoreVersion,
    ddsNettyBase: 'com.linkedin.dds-storage-core:dds-storage-netty4-base:' + ddsStorageCoreVersion,
    routerLnkd: 'com.linkedin.dds-storage-core:dds-storage-router-lnkd:' + ddsStorageCoreVersion,
    netty4Lnkd: 'com.linkedin.dds-storage-core:dds-storage-netty4-lnkd:' + ddsStorageCoreVersion,
    ddsStorageCommonBase: 'com.linkedin.dds-storage-core:dds-storage-common-base:' + ddsStorageCoreVersion,
    oss: 'org.sonatype.oss:oss-parent:7',
    asyncHttpClient: 'org.apache.httpcomponents:httpasyncclient:4.1.2',
    scalaLogging: 'com.typesafe.scala-logging:scala-logging_2.11:3.9.0',
    zookeeper: 'org.apache.zookeeper:zookeeper:3.4.6',
    zstd: 'com.github.luben:zstd-jni:1.4.4-7',

    // Hadoop to Venice Bridge dependencies
    mapreduceClientCore: 'org.apache.hadoop:hadoop-mapreduce-client-core:2.3.0',
    commonsConfiguration: 'commons-configuration:commons-configuration:1.9',
    commonsLang: 'commons-lang:commons-lang:2.6',
    hadoopCommon: 'org.apache.hadoop:hadoop-common:2.3.0',
    httpClient: 'org.apache.httpcomponents:httpclient:4.5.2',
    httpCore: 'org.apache.httpcomponents:httpcore:4.4.5',
    jacksonCore: 'org.codehaus.jackson:jackson-core-asl:1.9.6',
    jacksonMapper: 'org.codehaus.jackson:jackson-mapper-asl:1.9.6',
    javax: 'javax.servlet:javax.servlet-api:3.1.0',
    jdom: 'org.jdom:jdom:1.1',
    joptSimple: 'net.sf.jopt-simple:jopt-simple:3.2',
    log4j: 'log4j:log4j:1.2.17',
    log4j2api: 'org.apache.logging.log4j:log4j-api:2.9.1',
    log4j2core: 'org.apache.logging.log4j:log4j-core:2.9.1',
    snappy: 'org.xerial.snappy:snappy-java:1.0.4.1',
    // TODO: move back to open source sparkjava once they fix Jetty SSL.
    // spark: 'com.sparkjava:spark-core:2.9.1',
    spark: 'com.linkedin.li-sparkjava:li-sparkjava-impl:0.0.2',
    testng: 'org.testng:testng:6.14.3',
    tehuti: 'io.tehuti:tehuti:0.8.8',
    // Resolves java.lang.UnsupportedOperationException:  setXIncludeAware is not supported on this JAXP implementation or earlier: class org.apache.xerces.jaxp.DocumentBuilderFactoryImpl
    xalan: 'xalan:xalan:2.7.1',
    xerces: 'xerces:xercesImpl:2.9.1',

    // Hadoop to Venice Bridge test dependencies
    mapreduceClientJobClient: 'org.apache.hadoop:hadoop-mapreduce-client-jobclient:2.3.0',

    // Samza dependencies
    samzaApi: 'org.apache.samza:samza-api:1.5.0',

    // Added during dds-storage-core v2 => v3
    // Transitive dependency, to replace implicit version 11.0.17 which caused 4 test cases to fail:
    // 1. TestAdminSparkServer.controllerClientCanDeleteStore
    // 2. TestAdminSparkServer.controllerClientCanDeleteOldVersion
    // 3. TestAdminSparkServer.controllerClientCanDeleteAllVersion
    // 4. TestBrooklin.canReplicateKafkaWithBrooklinTopicReplicator
    restliDocgen: 'com.linkedin.pegasus:restli-docgen:15.1.10',

    // RocksDB
    rocksdbjni: 'org.rocksdb:rocksdbjni:6.6.4',

    // Flatbuffers lib, currently for benchmark only
    flatbuffersJava: 'com.google.flatbuffers:flatbuffers-java:1.11.0',

    // open source conscrypt from google
    conscrypt: 'org.conscrypt:conscrypt-openjdk-uber:2.4.0',
    classgraph: 'io.github.classgraph:classgraph:4.8.60',

    jmhCore: 'org.openjdk.jmh:jmh-core:1.28',
    jmhGenerator: 'org.openjdk.jmh:jmh-generator-annprocess:1.28'
]

subprojects {
  apply plugin: 'java-library'
  apply plugin: 'idea'
  apply plugin: 'jacoco'
  apply plugin: 'org.gradle.test-retry'

  sourceCompatibility = 1.8
  if (!project.hasProperty('overrideBuildEnvironment') || !project.overrideBuildEnvironment) {
     version = '0.1'
  }

  repositories {
    ivy {  //TODO: remove this before opensourcing
      url 'http://artifactory.corp.linkedin.com:8081/artifactory/release/'
      patternLayout {
        ivy '[organisation]/[module]/[revision]/[module]-[revision].ivy'
        artifact '[organisation]/[module]/[revision]/[artifact]-[revision](-[classifier]).[ext]'
        m2compatible = true
      }
    }
    mavenCentral() // when build fails, move this to first and then build, then move it back and build should work
    maven {
      url 'https://dl.bintray.com/linkedin/maven/'
    }
  }

  configurations {
    implementation {
      // These are global exclusions that will apply to the entire project
      exclude group: 'backport-util-concurrent'
      exclude group: 'com.intellij.annotations'
      exclude group: 'com.linkedin.avro-schemas'
      // exclude group: 'com.linkedin.container'
      exclude group: 'com.linkedin.container-core'
      exclude group: 'com.linkedin.linkedin-kafka-clients'
      exclude group: 'com.linkedin.util', module: 'util-sql'
      exclude module: 'kafka_2.10' // This ends up getting pulled in by a few dependencies, unfortunately :/ ...
      // exclude group: 'org.eclipse.jetty'
    }
    compileOnly {
      // These dependencies are transitively used at runtime, so we cannot exclude them further than compileOnly
      exclude group: 'com.google.guava', module: 'guava' // Used by Brooklin at runtime
    }
  }

  dependencies {
    implementation 'org.slf4j:slf4j-log4j12:1.7.14'
    implementation 'javax.validation:validation-api:1.0.0.GA'

    testImplementation libraries.testng
    testImplementation libraries.mockito
    // Test utils and framework for all unit tests and integration tests.
    testImplementation project(':venice-test-common')
  }

  idea {
    module {
      downloadJavadoc = true
      downloadSources = true
    }
  }

  tasks.withType(Test) {
    useTestNG() {
      excludeGroups 'flaky'
      Set<String> suiteListeners = ["com.linkedin.venice.testng.VeniceSuiteListener"]
      setListeners(suiteListeners)
    }

    retry {
      maxRetries = 4 // 5 attempts in total
      maxFailures = 100
      failOnPassedAfterRetry = false
    }

    forkEvery = Integer.valueOf(System.getProperty('forkEvery', '0'))
    maxParallelForks = Integer.valueOf(System.getProperty('maxParallelForks', '4'))
    minHeapSize = System.getProperty('minHeapSize', '1g')
    maxHeapSize = System.getProperty('maxHeapSize', '4g')

    doFirst {
      println "forkEvery=$forkEvery"
      println "maxParallelForks=$maxParallelForks"
      println "minHeapSize=$minHeapSize"
      println "maxHeapSize=$maxHeapSize"
    }

    testLogging {
      events 'started', 'passed', 'failed', 'skipped'
      showStandardStreams = false // to mute the DDS Router's noisy behavior...
      exceptionFormat = 'full'
    }
  }

  task flakyTests(type: Test) {
    useTestNG() {
      includeGroups 'flaky'
    }
    mustRunAfter test
  }
}

task unitTests {
  dependsOn subprojects.check
}

task flakyTests {
  dependsOn subprojects.flakyTests
  dependsOn 'venice-test-common:flakyIntegrationTests'
}

task integrationTests {
  dependsOn 'venice-test-common:integrationTests'
}

task buildAll {
  dependsOn unitTests
  dependsOn integrationTests
  dependsOn 'venice-common:buildJar'
  dependsOn 'venice-router:installDist'
  dependsOn 'venice-server:installDist'
  dependsOn 'venice-controller:installDist'
}

task compile {
  dependsOn compileJava
  dependsOn compileTestJava
  dependsOn 'venice-test-common:compileIntegrationTestJava'
}
