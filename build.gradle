import com.github.spotbugs.snom.SpotBugsTask
import org.apache.tools.ant.taskdefs.condition.Os
import org.gradle.internal.logging.text.StyledTextOutput.Style
import org.gradle.internal.logging.text.StyledTextOutputFactory

import java.nio.file.Files

plugins {
  id 'idea'
  id 'java'
  id 'maven-publish'
  id 'com.diffplug.spotless' version '6.12.0'
  id 'com.dorongold.task-tree' version '2.1.0'
  id 'com.github.johnrengelman.shadow' version '6.1.0' apply false
  id 'com.github.spotbugs' version '4.8.0' apply false
  id 'org.gradle.test-retry' version '1.5.0' apply false
  id 'com.form.diff-coverage' version '0.9.5' apply false
  id 'me.champeau.jmh' version '0.6.7' apply false
  id 'io.github.lhotari.gradle-nar-plugin' version '0.5.1' apply false
  id 'com.google.protobuf' version '0.9.3' apply false
}

apply from: "$rootDir/gradle/helper/git.gradle"
apply from: "$rootDir/gradle/helper/publishing.gradle"

/*
 * This snippet allows the Gradle environment to be overridden with custom
 * settings. This is useful in environments (such as a private company) where a
 * third party wishes to use custom repositories, or inject certain
 * functionality into the default Gradle build lifecycle.
 */
if (project.hasProperty('overrideBuildEnvironment')) {
  apply from: file(project.overrideBuildEnvironment)
  product {
    codeQuality {
      ignoreFailures = true
    }
  }
}

def avroVersion = '1.10.2'
def avroUtilVersion = '0.2.150'
def grpcVersion = '1.54.1'
def kafkaGroup = 'com.linkedin.kafka'
def kafkaVersion = '2.4.1.65'
def log4j2Version = '2.17.1'
def pegasusVersion = '29.31.0'
def protobufVersion = '3.21.7'
def jacksonVersion = '2.13.3'


ext.libraries = [
    avro: 'org.apache.avro:avro:' + avroVersion,
    avroCompiler: 'org.apache.avro:avro-compiler:' + avroVersion,
    avroMapred: 'org.apache.avro:avro-mapred:' + avroVersion,
    avroUtilBuilder: 'com.linkedin.avroutil1:builder:' + avroUtilVersion,
    avroUtilCompatHelper: 'com.linkedin.avroutil1:helper-all:' + avroUtilVersion,
    avroUtilFastserde: 'com.linkedin.avroutil1:avro-fastserde:' + avroUtilVersion,
    avroUtilSpotbugsPlugin: 'com.linkedin.avroutil1:spotbugs-plugin:0.2.69',
    bouncyCastle: 'org.bouncycastle:bcprov-jdk15on:1.55',
    caffeine: 'com.github.ben-manes.caffeine:caffeine:2.8.5',
    classgraph: 'io.github.classgraph:classgraph:4.8.60',
    commonsCodec: 'commons-codec:commons-codec:1.4',
    commonsConfiguration: 'commons-configuration:commons-configuration:1.9',
    commonsIo: 'commons-io:commons-io:2.11.0',
    commonsCli: 'commons-cli:commons-cli:1.5.0',
    commonsLang: 'commons-lang:commons-lang:2.6',
    conscrypt: 'org.conscrypt:conscrypt-openjdk-uber:2.5.2',
    d2: 'com.linkedin.pegasus:d2:' + pegasusVersion,
    failsafe: 'net.jodah:failsafe:2.4.0',
    fastUtil: 'it.unimi.dsi:fastutil:8.3.0',
    hadoopCommon: 'org.apache.hadoop:hadoop-common:2.3.0',
    helix: 'org.apache.helix:helix-core:1.0.4',
    httpAsyncClient: 'org.apache.httpcomponents:httpasyncclient:4.1.2',
    httpClient5: 'org.apache.httpcomponents.client5:httpclient5:5.2.1',
    httpCore5: 'org.apache.httpcomponents.core5:httpcore5:5.2.2',
    httpCore5H2: 'org.apache.httpcomponents.core5:httpcore5-h2:5.2.2',
    httpClient: 'org.apache.httpcomponents:httpclient:4.5.2',
    httpCore: 'org.apache.httpcomponents:httpcore:4.4.5',
    jacksonCore: 'com.fasterxml.jackson.core:jackson-core:' + jacksonVersion,
    jacksonAnnotations: 'com.fasterxml.jackson.core:jackson-annotations:' + jacksonVersion,
    jacksonDatabind: 'com.fasterxml.jackson.core:jackson-databind:' + jacksonVersion,
    javax: 'javax.servlet:javax.servlet-api:3.1.0',
    javaxActivation: 'com.sun.activation:javax.activation:1.2.0',
    jdom: 'org.jdom:jdom:1.1',
    jna: 'net.java.dev.jna:jna:4.5.1',
    jsr305: 'com.google.code.findbugs:jsr305:3.0.2',
    joptSimple: 'net.sf.jopt-simple:jopt-simple:3.2',
    kafka: kafkaGroup + ':kafka_2.12:' + kafkaVersion,
    kafkaClients: kafkaGroup + ':kafka-clients:' + kafkaVersion,
    kafkaClientsTest: kafkaGroup + ':kafka-clients:' + kafkaVersion + ':test',
    log4j2api: 'org.apache.logging.log4j:log4j-api:' + log4j2Version,
    log4j2core: 'org.apache.logging.log4j:log4j-core:' + log4j2Version,
    mail: 'javax.mail:mail:1.4.4',
    mapreduceClientCore: 'org.apache.hadoop:hadoop-mapreduce-client-core:2.3.0',
    mapreduceClientJobClient: 'org.apache.hadoop:hadoop-mapreduce-client-jobclient:2.3.0',
    mockito: 'org.mockito:mockito-core:3.3.3',
    netty: 'io.netty:netty-all:4.1.52.Final',
    oss: 'org.sonatype.oss:oss-parent:7',
    pulsarClient: "${pulsarGroup}:pulsar-client:${pulsarVersion}",
    pulsarIoCore: "${pulsarGroup}:pulsar-io-core:${pulsarVersion}",
    pulsarIoCommon: "${pulsarGroup}:pulsar-io-common:${pulsarVersion}",
    r2: 'com.linkedin.pegasus:r2:' + pegasusVersion,
    restliCommon: 'com.linkedin.pegasus:restli-common:' + pegasusVersion,
    rocksdbjni: 'org.rocksdb:rocksdbjni:7.9.2',
    samzaApi: 'org.apache.samza:samza-api:1.5.1',
    slf4j: 'org.slf4j:slf4j:1.7.36',
    slf4jApi: 'org.slf4j:slf4j-api:1.7.36',
    slf4jSimple: 'org.slf4j:slf4j-simple:1.7.36',
    snappy: 'org.iq80.snappy:snappy:0.4',
    spark: 'com.sparkjava:spark-core:2.9.4',
    spotbugs: 'com.github.spotbugs:spotbugs:4.5.2',
    tehuti: 'io.tehuti:tehuti:0.10.0',
    testcontainers: 'org.testcontainers:testcontainers:1.18.0',
    testng: 'org.testng:testng:6.14.3',
    // Resolves java.lang.UnsupportedOperationException:  setXIncludeAware is not supported on this JAXP implementation or earlier: class org.apache.xerces.jaxp.DocumentBuilderFactoryImpl
    xalan: 'xalan:xalan:2.7.1',
    xerces: 'xerces:xercesImpl:2.9.1',
    zkclient: 'com.101tec:zkclient:0.7', // For Kafka AdminUtils
    zookeeper: 'org.apache.zookeeper:zookeeper:3.5.9',
    zstd: 'com.github.luben:zstd-jni:1.5.2-3',
    grpcNettyShaded: 'io.grpc:grpc-netty-shaded:' + grpcVersion,
    grpcProtobuf: 'io.grpc:grpc-protobuf:' + grpcVersion,
    grpcStub: 'io.grpc:grpc-stub:' + grpcVersion,
    tomcatAnnotations: 'org.apache.tomcat:annotations-api:6.0.53',
]

group = 'com.linkedin.venice'

publishing {
  repositories {
    mavenLocal()
    maven {
      name 'LinkedInJFrog'
      url 'https://linkedin.jfrog.io/artifactory/venice'
      if (System.getenv('JFROG_USERNAME') != null && System.getenv('JFROG_API_KEY') != null) {
        credentials {
          username System.getenv('JFROG_USERNAME')
          password System.getenv('JFROG_API_KEY')
        }
      }
    }
  }
}

def parser = new XmlSlurper()
parser.setFeature("http://apache.org/xml/features/disallow-doctype-decl", false)
parser.setFeature("http://apache.org/xml/features/nonvalidating/load-external-dtd", false)

// We remove square brackets from test names, which occur when using a DataProvider,
// because occasionally the number in the brackets is non-deterministic (unknown why)
// and when that occurs, the test-retry plugin gets confused and cannot match the
// attempts together.
def removeSquareBrackets(String testName) {
  return testName.replaceFirst('\\[[0-9]+\\]', '')
}

subprojects {
  //apply group and version to all submodules
  group = rootProject.group
  version = rootProject.version

  def isLeafSubModule = project.childProjects.isEmpty()

  apply {
    plugin 'idea'
    plugin 'java-library'
    plugin 'com.github.spotbugs'
    plugin 'org.gradle.test-retry'
  }

  if (isLeafSubModule) {
    apply {
      plugin 'jacoco'
      plugin 'com.form.diff-coverage'
      plugin 'com.google.protobuf'
    }
  }

  if (JavaVersion.current() >= JavaVersion.VERSION_1_9) {
    tasks.withType(JavaCompile) {
      options.release = 8
    }
  }

  java {
    withSourcesJar()
    // TODO: Enable after we have valid javadocs
    //withJavadocJar()
  }

  if (isLeafSubModule) {
    protobuf {
      protoc {
        artifact = 'com.google.protobuf:protoc:' + protobufVersion
      }
      plugins {
        grpc {
          artifact = 'io.grpc:protoc-gen-grpc-java:' + grpcVersion
        }
      }
      generateProtoTasks {
        ofSourceSet('main')*.plugins {
          grpc {}
        }
      }
    }
  }

  configurations {
    implementation {
      // These are global exclusions that will apply to the entire project
      exclude group: 'backport-util-concurrent'
      exclude group: 'com.intellij.annotations'
      exclude group: 'com.linkedin.avro-schemas'
      exclude group: 'com.linkedin.container'
      exclude group: 'com.linkedin.container-core'
      exclude group: 'com.linkedin.security'
      exclude group: 'com.linkedin.dds-storage-core'
      exclude group: 'com.linkedin.linkedin-kafka-clients'
      exclude group: 'com.linkedin.util', module: 'util-sql'
      exclude group: 'org.slf4j', module: 'slf4j-log4j12'
      exclude module: 'clojure'
      exclude module: 'kafka_2.10' // This ends up getting pulled in by a few dependencies, unfortunately :/ ...
      exclude module: 'kafka_2.11'

      // These various netty modules clash with netty-all, and we transitively pull a different version, which causes NoSuchMethodError
      exclude group: 'io.netty', module: 'netty-buffer'
      exclude group: 'io.netty', module: 'netty-codec'
      exclude group: 'io.netty', module: 'netty-common'
      exclude group: 'io.netty', module: 'netty-handler'
      exclude group: 'io.netty', module: 'netty-resolver'
      exclude group: 'io.netty', module: 'netty-transport'
      exclude group: 'io.netty', module: 'netty-transport-native-epoll'
      exclude group: 'io.netty', module: 'netty-transport-native-unix-common'
    }
    compileOnly {
      // These dependencies are transitively used at runtime, so we cannot exclude them further than compileOnly
      exclude group: 'com.typesafe.scala-logging'
      exclude group: 'log4j'
      exclude group: 'org.slf4j'
    }
    all {
      resolutionStrategy.force libraries.zookeeper
    }
    avroCompiler {
    }
  }

  dependencies {
    testImplementation libraries.log4j2api
    testImplementation libraries.mockito
    testImplementation libraries.testng
    // Test utils and framework for all unit tests and integration tests.
    testImplementation project(':internal:venice-test-common')

    spotbugs libraries.spotbugs
    spotbugsPlugins libraries.avroUtilSpotbugsPlugin

    avroCompiler libraries.avroCompiler
    avroCompiler libraries.avroUtilBuilder
    avroCompiler 'org.slf4j:slf4j-simple:1.7.32'
    implementation libraries.grpcNettyShaded
    implementation libraries.grpcProtobuf
    implementation libraries.grpcStub
    compileOnly libraries.tomcatAnnotations
  }

  idea {
    module {
      downloadJavadoc = true
      downloadSources = true
    }
  }

  task compileAvro(type: SourceTask) {
    def sourceDir = file('src/main/resources/avro')
    def outputDir = file("$buildDir/generated/sources/avro/java/main")

    source sourceDir
    inputs.files(configurations.avroCompiler).withNormalizer(ClasspathNormalizer)
    outputs.dir(outputDir)
    outputs.cacheIf { true }

    doFirst {
      def versionOverrides = [
//        project(':internal:venice-common').file('src/main/resources/avro/StoreVersionState/v5', PathValidation.DIRECTORY)
      ]

      def schemaDirs = [sourceDir]
      sourceDir.eachDir { typeDir ->
        def parseVersionId = { dir ->
          (dir in versionOverrides) ? Integer.MAX_VALUE : dir?.name?.substring(1)?.toInteger()
        }
        def latestVersionDir = null
        typeDir.eachDirMatch(~/v-?\d+/) { versionDir ->
          if (parseVersionId(versionDir) > parseVersionId(latestVersionDir)) {
            latestVersionDir = versionDir
          }
        }
        if (latestVersionDir) {
          schemaDirs << latestVersionDir
        }
      }

      copy {
        from (schemaDirs) {
          include '*.avsc'
        }
        into temporaryDir
        duplicatesStrategy = DuplicatesStrategy.FAIL
        eachFile {
          println "Copying avro schema ${relativePath(it.file)} ${it.file.parentFile in versionOverrides ? '(OVERRIDE)' : ''}"
        }
      }

      javaexec {
        classpath = configurations.avroCompiler
        main = 'com.linkedin.avroutil1.builder.SchemaBuilder'
        args = [
            '--input', temporaryDir,
            '--output', outputDir
        ]
      }
    }
  }
  sourceSets.main.java.srcDir(compileAvro)

  tasks.withType(SpotBugsTask) {
    effort = 'max'
    reportLevel = 'low'
    includeFilter = file(
      project.hasProperty('spotallbugs') ?
        "$rootDir/gradle/spotbugs/include-all.xml" :
        "$rootDir/gradle/spotbugs/include.xml"
    )
    excludeFilter = file("$rootDir/gradle/spotbugs/exclude.xml")
    ignoreFailures = project.hasProperty('spotbugs.ignoreFailures')
    showStackTraces = false
    reports ({
      xml {
        enabled = project.hasProperty('spotbugs.xml')
      }
      html {
        enabled = !reports.getByName('XML').enabled
        stylesheet = 'fancy-hist.xsl'
      }
    })
    doFirst {
      sourceDirs += sourceSets.getByName(baseName).output.generatedSourcesDirs
      def generatedSources = sourceDirs.sum { dir ->
        dir.path =~ "^$buildDir/generated/sources/" ?
          fileTree(dir: dir, include: '**/*.java').collect { dir.relativePath(it) } : []
      }
      if (generatedSources) {
        def generatedClasses = generatedSources*.replaceFirst('.java$', '').sum {
          [ it + '.class', it + '\$*.class' ]
        }
        classes = classDirs.asFileTree.matching { exclude generatedClasses }
        auxClassPaths += classDirs.asFileTree.matching { include generatedClasses }.each {
          println "Excluding generated class ${project.relativePath(it)}"
        }
      }
    }
  }

  def ALPINI_TEST_FILTER = 'com.linkedin.alpini.*'
  def ALPINI_NETTY_TEST_FILTER = 'io.netty.*'
  def ALPINI_UNIT_TEST_TASK_NAME = 'alpiniUnitTest'
  def ALPINI_FUNCTIONAL_TEST_TASK_NAME = 'alpiniFunctionalTest'

  tasks.withType(Test) {
    mustRunAfter tasks.withType(SpotBugsTask)

    if (!project.ext.has("skipAlpnBoot") || !project.ext.skipAlpnBoot) {
      // The ALPN version should match the JVM version
      if (JavaVersion.current() < JavaVersion.VERSION_11) {
        if (Os.isFamily(Os.FAMILY_MAC)) {
          jvmArgs '-Xbootclasspath/p:/Library/Java/Boot/1_8_0_172/alpn-boot-8.1.12.v20180117.jar'
        } else if (Os.isFamily(Os.FAMILY_UNIX)) {
          jvmArgs '-Xbootclasspath/p:/export/apps/jdkboot/1_8_0_172/alpn-boot-8.1.12.v20180117.jar'
        } else {
          def osName = System.getProperty('os.name').toLowerCase(Locale.ENGLISH)
          throw new GradleException("$osName is not supported since ALPN only works for either Mac or Linux right now.")
        }
      }
    }

    forkEvery = Integer.valueOf(System.getProperty('forkEvery', '0'))
    maxParallelForks = Integer.valueOf(System.getProperty('maxParallelForks', '4'))
    minHeapSize = System.getProperty('minHeapSize', '1g')
    maxHeapSize = System.getProperty('maxHeapSize', '4g')

    systemProperty 'pubSubBrokerFactory', System.getProperty('pubSubBrokerFactory', "com.linkedin.venice.integration.utils.KafkaBrokerFactory")

    System.getProperty('jvmArgs')?.eachMatch(/(?:[^\s'"]+|'[^']*'|"[^"]*")+/) { jvmArgs it }

    doFirst {
      println "forkEvery=$forkEvery"
      println "maxParallelForks=$maxParallelForks"
      println "jvmArgs=$allJvmArgs"
    }

    if (name != ALPINI_UNIT_TEST_TASK_NAME && name != ALPINI_FUNCTIONAL_TEST_TASK_NAME) {
      filter {
        excludeTestsMatching ALPINI_TEST_FILTER
        excludeTestsMatching ALPINI_NETTY_TEST_FILTER
        failOnNoMatchingTests = false
      }
    }

    useTestNG {
      excludeGroups 'flaky'
      listeners = ['com.linkedin.venice.testng.VeniceSuiteListener']
    }

    retry {
      maxRetries = 4 // 5 attempts in total
      maxFailures = 100
      failOnPassedAfterRetry = false
    }

    testLogging {
      events = [] // N.B. we suppress all events as everything is taken care of in beforeTest and afterTest
      showStandardStreams = false // to mute the DDS Router's noisy behavior...
      exceptionFormat = 'full'
    }

    beforeTest { descriptor ->
      def testName = removeSquareBrackets(descriptor.displayName)
      def out = services.get(StyledTextOutputFactory).create("an-ouput")

      out.style(Style.Normal).println("$descriptor.className > $testName STARTED")
    }

    afterTest { descriptor, result ->
      def totalTime = result.endTime - result.startTime
      def prettyTime = totalTime < 1000 ? "$totalTime ms" : "${totalTime / 1000} s"
      def testName = removeSquareBrackets(descriptor.displayName)
      def out = services.get(StyledTextOutputFactory).create("an-ouput")

      def style = result.resultType == TestResult.ResultType.SUCCESS
        ? Style.Identifier
        : result.resultType == TestResult.ResultType.FAILURE
          ? Style.Failure
          : Style.Normal

      def status = result.resultType == TestResult.ResultType.SUCCESS
        ? 'PASSED '
        : result.resultType == TestResult.ResultType.FAILURE
          ? 'FAILED '
          : 'SKIPPED '

      out.style(Style.Normal).text("$descriptor.className > $testName ")
          .style(style).text(status)
          .style(Style.Normal).println("($prettyTime)")

      if (result.resultType == TestResult.ResultType.FAILURE) {
        def originalStacktrace = result.exception.getStackTrace()
        ArrayList<StackTraceElement> truncatedStackTrace = []
        for (int i = 0; i < originalStacktrace.length; i++) {
          def element = originalStacktrace[i]
          def className = element.getClassName()
          if (i > 1 && (className.startsWith('org.gradle') || className.startsWith('jdk.internal'))) {
            break
          }
          truncatedStackTrace[i] = element
        }
        def truncatedException = result.exception
        truncatedException.setStackTrace(truncatedStackTrace.toArray(new StackTraceElement[0]))
        out.text('    ').exception(truncatedException)
      }
    }
  }

  if (isLeafSubModule) {
    jacocoTestReport {
      dependsOn test // tests are required to run before generating the report

      reports {
        xml.enabled = true
        html.enabled = true
      }

      doLast {
        parseJacocoXml("$buildDir/reports/jacoco/test/jacocoTestReport.xml")
      }
    }

    afterEvaluate {
      jacocoTestCoverageVerification {
        dependsOn jacocoTestReport

        violationRules {
          rule {
            def threshold = project.ext.has('jacocoCoverageThreshold') ? project.ext.jacocoCoverageThreshold : 0.6

            limit {
              counter = 'BRANCH'
              value = 'COVEREDRATIO'
              minimum = threshold
            }
          }
        }
      }

      diffCoverageReport {
        diffSource.file = createDiffFile()

        // Report locates at <module_name>/build/reports/jacoco/diffCoverage/html/index.html
        reports {
          html = true
          xml = true
        }

        violationRules {
          minBranches = project.ext.has('diffCoverageThreshold') ? project.ext.diffCoverageThreshold : 0.40
          failOnViolation = true
        }
      }

      task logDiffCoverage {
        doLast {
          parseJacocoXml("$buildDir/reports/jacoco/diffCoverage/report.xml")
        }
      }

      diffCoverage.dependsOn jacocoTestReport
      diffCoverage.finalizedBy logDiffCoverage
    }
  }

  task flakyTest(type: Test) {
    useTestNG {
      includeGroups 'flaky'
    }
  }

  task "$ALPINI_UNIT_TEST_TASK_NAME"(type: Test) {
    useTestNG() {
      includeGroups 'unit'
    }
    filter {
      includeTestsMatching ALPINI_TEST_FILTER
      includeTestsMatching ALPINI_NETTY_TEST_FILTER
      failOnNoMatchingTests = false
    }
  }

  task "$ALPINI_FUNCTIONAL_TEST_TASK_NAME"(type: Test) {
    useTestNG() {
      includeGroups 'functional'
    }
    filter {
      includeTestsMatching ALPINI_TEST_FILTER
      includeTestsMatching ALPINI_NETTY_TEST_FILTER
      failOnNoMatchingTests = false
    }
  }

  tasks.withType(Jar) {
    zip64 = true
    duplicatesStrategy = DuplicatesStrategy.FAIL
    exclude('**/*.xml')
  }

  task testJar(type: Jar) {
    classifier 'tests'
    from sourceSets.test.output
  }

  // Only publish artifacts for projects that are at the leaf level
  if (isLeafSubModule) {
    publishing.configureArtifactPublishing(project, testJar)
  }
}

task aggregateJavadoc(type: Javadoc) {
  source subprojects.collect { project ->
    project.sourceSets.main.allJava
  }
  classpath = files(subprojects.collect { project ->
    project.sourceSets.main.compileClasspath
  })
  // generate javadoc with no warnings
  getOptions().addStringOption('Xdoclint:none', '-quiet')
  destinationDir = new File(buildDir, 'javadoc')
}

spotless {
  ratchetFrom "${git.getUpstreamRemote()}/main"
  java {
    importOrder()
    removeUnusedImports()
    eclipse().configFile("$rootDir/gradle/spotless/eclipse-java-formatter.xml")
    target '**/*.java'
    targetExclude '**/generated/**'
  }
}

task setupWorkspace {
  println 'Setting up default git config'
  def gitConfig = [
      'core.hooksPath' : 'gradle/githooks',
      'blame.ignoreRevsFile' : '.git-blame-ignore-revs',
      'branch.autoSetupMerge' : 'true', // Only track remote branches
      'branch.autoSetupRebase' : 'always',
      'pull.rebase' : 'true',
  ]
  gitConfig.each(git.setConfig)
}

task spotbugs {
  dependsOn subprojects.tasks*.withType(SpotBugsTask)
}
check.dependsOn(spotbugs)

test {
  mustRunAfter spotbugs
  dependsOn subprojects.test
  afterTest { descriptor, result ->
    def totalTime = result.endTime - result.startTime
    println "Total time of $descriptor.name was $totalTime"
  }
}

assemble {
  dependsOn (
    setupWorkspace,
    testClasses,
    'internal:venice-test-common:jmhClasses',
    'internal:venice-test-common:integrationTestClasses'
  )
}

build {
  dependsOn (
    'services:venice-router:installDist',
    'services:venice-server:installDist',
    'services:venice-controller:installDist'
  )
}

idea.project.ipr {
  withXml { provider ->
    provider.node.component
            .find { it.@name == 'VcsDirectoryMappings' }
            .mapping.@vcs = 'Git'

    def inspectionProjectProfileManager = provider.node.component
        .find { it.@name == 'InspectionProjectProfileManager' }

    def danglingJavaDocInspectionProperties = [
      class: "DanglingJavadoc",
      enabled: "false",
      level: "WARNING",
      enabled_by_default: "false"
    ]

    if (inspectionProjectProfileManager == null) {
      inspectionProjectProfileManager = provider.node.appendNode(
        "component",
        [
          name: "InspectionProjectProfileManager"
        ]
      )

      def profile = inspectionProjectProfileManager.appendNode(
        "profile",
        [
          version: "1.0"
        ]
      )

      profile.appendNode(
        "option",
        [
          name: "myName",
          value: "Project Default"
        ]
      )

      profile.appendNode(
        "inspection_tool",
        danglingJavaDocInspectionProperties
      )

      inspectionProjectProfileManager.appendNode(
        "version",
        [
          value: "1.0"
        ]
      )
    } else {
      def danglingJavaDoc = inspectionProjectProfileManager.profile.inspection_tool
          .find { it.@class == 'DanglingJavadoc' }
      if (danglingJavaDoc == null) {
        inspectionProjectProfileManager.profile.get(0).appendNode(
          "inspection_tool",
          danglingJavaDocInspectionProperties
        )
      } else {
        danglingJavaDoc.@enabled = false
        danglingJavaDoc.@level = "WARNING"
        danglingJavaDoc.@enabled_by_default = false
      }
    }
  }
}

// Allow running diffCoverage against uncommitted files
// See https://github.com/form-com/diff-coverage-gradle/issues/73
ext.createDiffFile = { ->
  // Files that we don't plan to write unit tests for now. Will be worked in the future
  def exclusionFilter = [
      // Keep this sorted
      // da-vinci-client
      ':!clients/da-vinci-client/src/main/java/com/linkedin/davinci/DaVinciBackend.java',

      // venice-client
      ':!clients/venice-client/src/main/java/com/linkedin/venice/fastclient/factory/ClientFactory.java',
      // unit test for gRPC Transport Client is not straightforward, adding to exclusion list for now
      ':!clients/venice-client/src/main/java/com/linkedin/venice/fastclient/transport/GrpcTransportClient.java',

      // venice-producer
      ':!clients/venice-producer/src/main/java/com/linkedin/venice/producer/online/OnlineProducerFactory.java',
      ':!clients/venice-producer/src/main/java/com/linkedin/venice/producer/online/ProducerTool.java',

      // venice-common
      ':!internal/venice-common/src/main/java/com/linkedin/venice/controllerapi/ControllerClient.java',

      // venice-test-common
      ':!internal/venice-test-common/*',

      // venice-controller
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceController.java',
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceControllerService.java',
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceHelixAdmin.java',
      ':!services/venice-controller/src/main/java/com/linkedin/venice/controller/VeniceParentHelixAdmin.java',

      // venice-router
      ':!services/venice-router/src/main/java/com/linkedin/venice/router/RouterServer.java',
      ':!services/venice-router/src/main/java/com/linkedin/venice/router/streaming/VeniceChunkedResponse.java',

      // venice-server
      ':!services/venice-server/src/main/java/com/linkedin/venice/server/VeniceServer.java',

      // venice-standalone
      ':!services/venice-standalone/*', // exclude the entire standalone project

      // Keep this last
      // Other files that have tests but are not executed in the regular unit test task
      ':!internal/alpini/*'
  ]
  def file = Files.createTempFile(URLEncoder.encode(project.name, 'UTF-8'), '.diff').toFile()
  def diffBase = "${git.getUpstreamRemote()}/main"
  def command = [
      'git', 'diff', diffBase, '--no-color', '--minimal', '--', '.'
  ]
  command.addAll(exclusionFilter)
  file.withOutputStream { out ->
    exec {
      commandLine command
      standardOutput = out
    }
  }

  return file
}

// for a given xml jacoco report, parse it and print out the branch coverage
ext.parseJacocoXml = { filePath ->
  try {
    def jacocoReport = parser.parse(filePath).children()
    def branchCoverage = jacocoReport.find { it.name() == 'counter' && it.@type == 'BRANCH' }
    def branchCoverageRatio = branchCoverage.@covered.toDouble() / (branchCoverage.@missed.toDouble() + branchCoverage.@covered.toDouble())
    println "Branch coverage: ${(branchCoverageRatio * 100.0).round(2)}%"
  } catch (Exception e) {
    // failure to retrieve numbers should not fail the build
    project.logger.debug("Branch coverage: N/A. There's either no branch coverage or " +
        "the jacoco report is not generated.", e)
  }
}

allprojects {
  task printAllDependencies(type: DependencyReportTask) {}
}
