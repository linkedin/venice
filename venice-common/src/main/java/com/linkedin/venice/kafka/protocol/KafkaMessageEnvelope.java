/**
 * Autogenerated by Avro
 * 
 * DO NOT EDIT DIRECTLY
 */
package com.linkedin.venice.kafka.protocol;

@SuppressWarnings("all")
public class KafkaMessageEnvelope extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  public static final org.apache.avro.Schema SCHEMA$ = org.apache.avro.Schema.parse("{\"type\":\"record\",\"name\":\"KafkaMessageEnvelope\",\"namespace\":\"com.linkedin.venice.kafka.protocol\",\"fields\":[{\"name\":\"messageType\",\"type\":\"int\",\"doc\":\"Using int because Avro Enums are not evolvable. Readers should always handle the 'unknown' value edge case, to account for future evolutions of this protocol. The mapping is the following: 0 => Put, 1 => Delete, 2 => ControlMessage.\"},{\"name\":\"producerMetadata\",\"type\":{\"type\":\"record\",\"name\":\"ProducerMetadata\",\"fields\":[{\"name\":\"producerGUID\",\"type\":{\"type\":\"fixed\",\"name\":\"GUID\",\"size\":16},\"doc\":\"A unique identifier for this producer.\"},{\"name\":\"segmentNumber\",\"type\":\"int\",\"doc\":\"A number used to disambiguate between sequential segments sent into a given partition by a given producer. An incremented SegmentNumber should only be sent following an EndOfSegment control message. For finite streams (such as those bulk-loaded from Hadoop), it can be acceptable to have a single SegmentNumber per producer/partition combination, though that is not something that the downstream consumer should assume. For infinite streams, segments should be terminated and begun anew periodically. This number begins at 0.\"},{\"name\":\"messageSequenceNumber\",\"type\":\"int\",\"doc\":\"A monotonically increasing number with no gaps used to distinguish unique messages produced in this segment (i.e.: by this producer into a given partition). This number begins at 0 (with a StartOfSegment ControlMessage) and subsequent messages (such as Put) will have a SequenceNumber of 1 and so forth.\"},{\"name\":\"messageTimestamp\",\"type\":\"long\",\"doc\":\"The time of the producer's local system clock, at the time the message was submitted for production. This is the number of milliseconds from the unix epoch, 1 January 1970 00:00:00.000 UTC.\"}]},\"doc\":\"ProducerMetadata contains information that the consumer can use to identify an upstream producer. This is common for all MessageType.\"},{\"name\":\"payloadUnion\",\"type\":[{\"type\":\"record\",\"name\":\"Put\",\"fields\":[{\"name\":\"schemaId\",\"type\":\"int\",\"doc\":\"An identifier used to determine how the PutValue can be deserialized.\"},{\"name\":\"putValue\",\"type\":\"bytes\",\"doc\":\"The record's value to be persisted in the storage engine.\"}]},{\"type\":\"record\",\"name\":\"Delete\",\"fields\":[]},{\"type\":\"record\",\"name\":\"ControlMessage\",\"fields\":[{\"name\":\"controlMessageType\",\"type\":\"int\",\"doc\":\"Using int because Avro Enums are not evolvable. Readers should always handle the 'unknown' value edge case, to account for future evolutions of this protocol. The mapping is the following: 0 => StartOfPush, 1 => EndOfPush, 2 => StartOfSegment, 3 => EndOfSegment, 4 => StartOfBufferReplay.\"},{\"name\":\"debugInfo\",\"type\":{\"type\":\"map\",\"values\":\"string\"},\"doc\":\"This metadata is for logging and traceability purposes. It can be used to propagate information about the producer, the environment it runs in, or the source of data being produced into Venice. There should be no assumptions that any of this data will be used (or even looked at) by the downstream consumer in any particular way.\"},{\"name\":\"controlMessageUnion\",\"type\":[{\"type\":\"record\",\"name\":\"StartOfPush\",\"fields\":[{\"name\":\"sorted\",\"type\":\"boolean\",\"doc\":\"Whether the messages inside current topic partition between 'StartOfPush' control message and 'EndOfPush' control message is lexicographically sorted by key bytes\",\"default\":false},{\"name\":\"chunked\",\"type\":\"boolean\",\"doc\":\"Whether the messages inside the current push are encoded with chunking support. If true, this means keys will be prefixed with ChunkId, and values may contain a ChunkedValueManifest (if schema is defined as -20).\",\"default\":false},{\"name\":\"compressionStrategy\",\"type\":\"int\",\"doc\":\"What type of compression strategy the current push are used. Using int because Avro Enums are not evolvable. The mapping is the following: 0 => NO_OP, 1 => GZIP\",\"default\":0}]},{\"type\":\"record\",\"name\":\"EndOfPush\",\"fields\":[]},{\"type\":\"record\",\"name\":\"StartOfSegment\",\"fields\":[{\"name\":\"checksumType\",\"type\":\"int\",\"doc\":\"Using int because Avro Enums are not evolvable. Readers should always handle the 'unknown' value edge case, to account for future evolutions of this protocol. The downstream consumer is expected to compute this checksum and use it to validate the incoming stream of data. The current mapping is the following: 0 => None, 1 => MD5, 2 => Adler32, 3 => CRC32.\"},{\"name\":\"upcomingAggregates\",\"type\":{\"type\":\"array\",\"items\":\"string\"},\"doc\":\"An array of names of aggregate computation strategies for which there will be a value percolated in the corresponding EndOfSegment ControlMessage. The downstream consumer may choose to compute these aggregates on its own and use them as additional validation safeguards, or it may choose to merely log them, or even ignore them altogether.\"}]},{\"type\":\"record\",\"name\":\"EndOfSegment\",\"fields\":[{\"name\":\"checksumValue\",\"type\":\"bytes\",\"doc\":\"The value of the checksum computed since the last StartOfSegment ControlMessage.\"},{\"name\":\"computedAggregates\",\"type\":{\"type\":\"array\",\"items\":\"long\"},\"doc\":\"A map containing the results of the aggregate computation strategies that were promised in the previous StartOfSegment ControlMessage. The downstream consumer may choose to compare the value of these aggregates against those that it computed on its own ir oder to use them as additional validation safeguards, or it may choose to merely log them, or even ignore them altogether.\"},{\"name\":\"finalSegment\",\"type\":\"boolean\",\"doc\":\"This field is set to true when the producer knows that there is no more data coming from its data source after this EndOfSegment. This happens at the time the producer is closed.\"}]},{\"type\":\"record\",\"name\":\"StartOfBufferReplay\",\"fields\":[{\"name\":\"sourceOffsets\",\"type\":{\"type\":\"array\",\"items\":\"long\"},\"doc\":\"Array of offsets from the real-time buffer topic at which the Buffer Replay Service started replaying data. The index position of the array corresponds to the partition number in the real-time buffer.\"},{\"name\":\"sourceKafkaCluster\",\"type\":\"string\",\"doc\":\"Kafka bootstrap servers URL of the cluster where the source buffer exists.\"},{\"name\":\"sourceTopicName\",\"type\":\"string\",\"doc\":\"Name of the source buffer topic.\"}]}],\"doc\":\"This contains the ControlMessage data which is specific to each type of ControlMessage. Which branch of the union is present is based on the previously-defined MessageType field.\"}]}],\"doc\":\"This contains the main payload of the message. Which branch of the union is present is based on the previously-defined MessageType field.\"}]}");
  /** Using int because Avro Enums are not evolvable. Readers should always handle the 'unknown' value edge case, to account for future evolutions of this protocol. The mapping is the following: 0 => Put, 1 => Delete, 2 => ControlMessage. */
  public int messageType;
  /** ProducerMetadata contains information that the consumer can use to identify an upstream producer. This is common for all MessageType. */
  public com.linkedin.venice.kafka.protocol.ProducerMetadata producerMetadata;
  /** This contains the main payload of the message. Which branch of the union is present is based on the previously-defined MessageType field. */
  public java.lang.Object payloadUnion;
  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call. 
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return messageType;
    case 1: return producerMetadata;
    case 2: return payloadUnion;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }
  // Used by DatumReader.  Applications should not call. 
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: messageType = (java.lang.Integer)value$; break;
    case 1: producerMetadata = (com.linkedin.venice.kafka.protocol.ProducerMetadata)value$; break;
    case 2: payloadUnion = (java.lang.Object)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }
}
