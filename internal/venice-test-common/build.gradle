import java.nio.file.Files
import java.nio.file.Path
import java.nio.file.Paths
import java.nio.file.StandardCopyOption
import java.nio.file.StandardOpenOption


apply {
  plugin 'me.champeau.jmh'
}

jmh {
  fork = 3
  warmupForks = 1
  iterations = 10
  warmupIterations = 5
  timeUnit = 'ns'
  resultFormat = 'json'
  failOnError = true
  includeTests = false
  profilers = ['gc']
  benchmarkMode = ['sample']
  includes = ['DaVinciClientBenchmark']
  jvmArgs = ['-Xms4G', '-Xmx4G', '-Djmh.shutdownTimeout=0', '-Djmh.shutdownTimeout.step=0']
}

jmhJar {
  zip64 = true
}

configurations {
  all {
    resolutionStrategy {
      force libraries.kafka
      force libraries.javax
    }
  }
  implementation {
    exclude group: 'org.apache.kafka'
    exclude group: 'org.mortbay.jetty', module: 'servlet-api'
  }
  integrationTestImplementation.extendsFrom testImplementation
  integrationTestUtils
}

sourceSets {
  integrationTest {
    // 'src/integrationTest/java' is in srcDir by default. Just add the proto directory
    java.srcDir 'src/integrationTest/proto'
    resources
  }
  jmh {
    // 'src/jmh/java' is in srcDir by default. Just add the proto directory
    java.srcDir 'src/jmh/proto'
    resources
  }
}

dependencies {
  implementation (libraries.d2) {
    exclude group: 'com.oracle', module: 'ojdbc14' // unused transitive dependencies, doesn't exist in repo
    // this will introduce another different mockito-all version
    exclude group: 'org.mockito', module: 'mockito-all'
  }
  implementation project(':clients:da-vinci-client')
  implementation project(':clients:venice-client')
  implementation project(':clients:venice-push-job')
  implementation project(':internal:venice-common')
  implementation project(':services:venice-controller')
  implementation project(':services:venice-router')
  implementation project(':clients:venice-samza')
  implementation project(':clients:venice-producer')
  implementation project(':internal:venice-client-common')
  implementation project(':services:venice-server')
  implementation project(':clients:venice-thin-client')
  implementation project(':internal:alpini:netty4:alpini-netty4-base')
  implementation project(':internal:alpini:router:alpini-router-api')
  implementation project(':internal:alpini:router:alpini-router-base')

  implementation('org.apache.helix:helix-core:1.4.1:jdk8') {
    exclude group: 'org.apache.helix'
  }
  implementation('org.apache.helix:helix-common:1.4.1:jdk8')  {
    exclude group: 'org.apache.helix'
  }
  implementation('org.apache.helix:zookeeper-api:1.4.1:jdk8') {
    exclude group: 'org.apache.helix'
  }
  implementation('org.apache.helix:metadata-store-directory-common:1.4.1:jdk8') {
    exclude group: 'org.apache.helix'
  }
  implementation('org.apache.helix:metrics-common:1.4.1:jdk8')

  implementation libraries.avroUtilCompatHelper
  implementation libraries.avroUtilFastserde
  implementation libraries.commonsCli
  implementation libraries.conscrypt
  implementation libraries.fastUtil
  implementation (libraries.hadoopCommon) {
    exclude group: 'javax.servlet'
  }
  implementation libraries.httpAsyncClient
  implementation libraries.javax
  implementation libraries.kafka
  implementation libraries.kafkaClients
  implementation libraries.kafkaClientsTest
  implementation libraries.mockito
  implementation libraries.rocksdbjni
  implementation libraries.samzaApi
  implementation libraries.spark
  implementation libraries.testng

  implementation (libraries.mapreduceClientJobClient) {
    exclude group: 'org.apache.avro'
    exclude group: 'javax.servlet'
  }
  testImplementation project(':clients:venice-admin-tool')
  testImplementation project(':internal:alpini:common:alpini-common-base')
  testImplementation project(':internal:venice-common').sourceSets.test.output
  testImplementation libraries.log4j2core
  testImplementation libraries.log4j2api

  jmhAnnotationProcessor 'org.openjdk.jmh:jmh-generator-annprocess:' + jmh.jmhVersion.get()
  jmhImplementation project(path: ':internal:venice-test-common', configuration: 'integrationTestUtils')
}

def integrationTestConfigs = {
  mustRunAfter test
  classpath = sourceSets.integrationTest.runtimeClasspath
  testClassesDirs = sourceSets.integrationTest.output.classesDirs
  forkEvery = Integer.parseInt(project.properties.get('integrationTest.forkEvery', "$forkEvery"))
  maxParallelForks = Integer.parseInt(project.properties.get('integrationTest.maxParallelForks', "$maxParallelForks"))
}

def integrationTestBuckets = [
  "1000": [
      "com.linkedin.davinci.*",
      "com.linkedin.venice.endToEnd.DaVinciClientDiskFullTest",
      "com.linkedin.venice.endToEnd.DaVinciClientMemoryLimitTest"],
  "1010": [
       "com.linkedin.venice.endToEnd.DaVinciClientTest"],
  "1020": [
      "com.linkedin.venice.endToEnd.DaVinciCluster*",
      "com.linkedin.venice.endToEnd.DaVinciCompute*",
      "com.linkedin.venice.endToEnd.DaVinciLive*"],
  "1030": [
      "com.linkedin.venice.consumer.*"],
  "1040": [
      "com.linkedin.venice.endToEnd.ActiveActive*"],
  "1050": [
      "com.linkedin.venice.endToEnd.TestActiveActive*"],
  "1060": [
      "com.linkedin.venice.helix.*",
      "com.linkedin.venice.helixrebalance.*"],
  "1070": [
      "com.linkedin.venice.fastclient.*"],
  "1080": [
      "com.linkedin.venice.endToEnd.TestEmptyPush",
      "com.linkedin.venice.ingestionHeartbeat.*"],
  "1090": [
      "com.linkedin.venice.router.*"
        ],
  "1100": [
      "com.linkedin.venice.server.*"],
  "1110": [
      "com.linkedin.venice.restart.*"],
  "1120": [
      "com.linkedin.venice.storagenode.*"],
  "1130": [
      "com.linkedin.venice.endToEnd.TestStoreMigration",
      "com.linkedin.venice.endToEnd.TestStuckConsumerRepair",
      "com.linkedin.venice.endToEnd.TestSuperSetSchemaRegistration",
      "com.linkedin.venice.endToEnd.TestTopicWiseSharedConsumerPoolResilience",
      "com.linkedin.venice.endToEnd.TestUnusedValueSchemaCleanup",
      "com.linkedin.venice.endToEnd.BlobP2PTransferAmongServersTest"],
  "1200":[
      "com.linkedin.venice.endToEnd.TestVson*",
      "com.linkedin.venice.endToEnd.Push*"],
  "1210": [
      "com.linkedin.venice.hadoop.*"],
  "1220": [
      "com.linkedin.venice.endToEnd.TestPushJob*"],
  "1230": [
      "com.linkedin.venice.endToEnd.TestBatch*"],
  "1240": [
      "com.linkedin.venice.kafka.*",
      "com.linkedin.venice.samza.*",
      "com.linkedin.venice.writer.*"],
  "1250": [
      "com.linkedin.venice.endToEnd.PartialUpdateTest"],
  "1260": [
      "com.linkedin.venice.endToEnd.PartialUpdateWithParallelProcessingTest"],
  "1270": [
      "com.linkedin.venice.endToEnd.TestWritePathComputation",
      "com.linkedin.venice.endToEnd.WriteComputeWithActiveActiveReplicationTest",
      "com.linkedin.venice.endToEnd.StoragePersona*",
      "com.linkedin.venice.endToEnd.TestStoreUpdateStoragePersona",
      "com.linkedin.venice.persona.*"],
  "1280": [
      "com.linkedin.venice.pubsub.*"],
  "1400": [
      "com.linkedin.venice.endToEnd.TestHybrid*"],
  "1410": [
      "com.linkedin.venice.controller.server.*",
      "com.linkedin.venice.controller.kafka.consumer.*",
      "com.linkedin.venice.controller.migration.*"],
  "1420": [
      "com.linkedin.venice.controller.AdminTool*",
      "com.linkedin.venice.controller.VeniceParentHelixAdminTest"],
  "1430": [
      "com.linkedin.venice.controller.Test*"],
  "1440": [
      "com.linkedin.venice.endToEnd.DataRecoveryTest",
      "com.linkedin.venice.controllerapi.TestControllerClient"],
  "1500":[
      "com.linkedin.venice.multicluster.TestMetadataOperationInMultiCluster",
      "com.linkedin.venice.endToEnd.MetaSystemStoreTest",
      "com.linkedin.venice.zk.TestMigrateVeniceZKPaths",
      "com.linkedin.venice.throttle.TestRouterReadQuotaThrottler"],
  "1550": [
        "com.linkedin.venice.stats.TestZkClientStatusStats",
        "com.linkedin.venice.multicluster.TestMetadataOperationInMultiCluster",
        "com.linkedin.venice.integration.utils.SystemExitPrevention",
        "com.linkedin.venice.integration.StorageNodeServiceTest",
        "com.linkedin.venice.endToEnd.TestStoreGraveyardCleanupService",
        "com.linkedin.venice.endToEnd.TestStoreBackupVersionDeletion",
        "com.linkedin.venice.endToEnd.TestStaleDataVisibility"]
]

integrationTestBuckets.each { name, patterns ->
  task "integrationTests_${name}" (type: Test) {
    ext {
      suiteStartTime = 0
    }
    filter {
      patterns.each { pattern ->
        includeTestsMatching pattern
      }
    }
    configure integrationTestConfigs
    useTestNG {
      excludeGroups 'flaky'
      listeners = ['com.linkedin.venice.testng.VeniceSuiteListener', 'com.linkedin.venice.testng.VeniceTestListener']
    }
    beforeSuite { descriptor ->
      suiteStartTime = System.currentTimeMillis()
    }
    afterSuite { descriptor, result ->
      if (descriptor.name.startsWith("com.linkedin")) {
        println "Test Suite ${descriptor.name} completed (${result.getResultType()}) in ${(System.currentTimeMillis() - suiteStartTime )/1000} s"
      }
    }
  }
}

task integrationTests_9999(type: Test) {
  ext {
    suiteStartTime = 0
  }
  filter {
    integrationTestBuckets.each { name, patterns ->
      patterns.each { pattern ->
        excludeTestsMatching pattern
      }
    }
  }
  beforeSuite { descriptor ->
    suiteStartTime = System.currentTimeMillis()
  }
  configure integrationTestConfigs
  useTestNG {
    excludeGroups 'flaky'
    listeners = ['com.linkedin.venice.testng.VeniceSuiteListener', 'com.linkedin.venice.testng.VeniceTestListener']
  }
  afterSuite { descriptor, result ->
    if (descriptor.name.startsWith("com.linkedin")) {
      println "Test Suite ${descriptor.name} completed (${result.getResultType()}) in ${(System.currentTimeMillis() - suiteStartTime )/1000} s"
    }
  }
}

task generateGHCI() {
  def targetDir = rootDir.getPath() + "/.github/rawWorkflows/"
  def targetFile = new File(targetDir, "VeniceCI-E2ETests.yml")
  def targetFilePath = Paths.get(targetFile.getPath())

  def paramFile = new File(targetDir, "gh-ci-parameterized-flow.txt")
  def paramFilePath = Paths.get(paramFile.getPath())
  def paramFileContent = new String(Files.readAllBytes(paramFilePath))

  def completionFile = new File(targetDir, "gh-ci-completion-flow.txt")
  def completionFileContent = new String(Files.readAllBytes(Paths.get(completionFile.getPath())))

  targetFile.delete()
  targetFile.createNewFile()

  append(targetFilePath, "# Auto-generated file. Do not edit manually!\n#\n")
  append(targetFilePath, "# To alter these flows, edit:\n#\n#     internal/venice-test-common/build.gradle\n#\n")
  append(targetFilePath, "# To regenerate, run:\n#\n#     ./gradlew generateGHCI\n\n")

  append(targetFilePath, "name: E2ETests\n\n")
  append(targetFilePath, "on: [push, pull_request, workflow_dispatch]\n\n")
  append(targetFilePath, "jobs:\n")

  def jobs = []

  def common = "--continue --no-daemon "

  def integTestGradleArgs = common + "-DforkEvery=1 -DmaxParallelForks=1 integrationTests_"
  integrationTestBuckets.each { name, patterns ->
    def flowName = "IntegrationTests_" + name
    jobs << flowName
    appendToGHCI(paramFileContent, targetFilePath, flowName, 120, integTestGradleArgs + name)
  }
  def otherTest = "IntegrationTests_9999"
  appendToGHCI(paramFileContent, targetFilePath, otherTest, 120, integTestGradleArgs + "9999")
  jobs << otherTest

  // define a job that depends others to manage the status check
  appendToGHCI(completionFileContent, targetFilePath, "E2ETestsCompletion", 20, "null", jobs)

  def finalDestinationPath = Paths.get(rootDir.getPath() + "/.github/workflows/VeniceCI-E2ETests.yml")
  Files.move(targetFilePath, finalDestinationPath, StandardCopyOption.REPLACE_EXISTING)
}

def appendToGHCI(String paramFileContent, Path targetFilePath, String flowName, int timeOut, String gradleArguments, ArrayList dependency=null, String conditional=null) {
  String postProcessing = paramFileContent
      .replace("\$FlowName", flowName)
      .replace("\$TimeOut", Integer.toString(timeOut))
      .replace("\$GradleArguments", gradleArguments)

  if (dependency == null) {
    postProcessing = postProcessing.replace("    needs: \$Dependency\n", "")
  } else {
    postProcessing = postProcessing.replace("\$Dependency", dependency.toString())
  }

  if (conditional == null) {
    postProcessing = postProcessing.replace("    if: \$Conditional\n", "")
  } else {
    postProcessing = postProcessing.replace("\$Conditional", conditional.toString())
  }

  append(targetFilePath, postProcessing)
  append(targetFilePath, "\n")
}

def append(Path targetFilePath, String content) {
  Files.write(targetFilePath, content.getBytes(), StandardOpenOption.APPEND)
}

task integrationTest(type: Test) {
  configure integrationTestConfigs
}
check.dependsOn(integrationTest)

flakyTest {
  classpath += sourceSets.integrationTest.runtimeClasspath
  testClassesDirs += sourceSets.integrationTest.output.classesDirs
}

idea {
  module {
    testSourceDirs += project.sourceSets.integrationTest.java.srcDirs
    testSourceDirs += project.sourceSets.jmh.java.srcDirs

    testResourceDirs += project.sourceSets.integrationTest.resources.srcDirs
  }
}

task integrationTestJar(type: Jar) {
  classifier 'integrationTest'
  from sourceSets.integrationTest.output
}

artifacts {
  integrationTestUtils integrationTestJar
}

ext {
  jacocoCoverageThreshold = 0.00
  diffCoverageThreshold = 0.00
}

publishing {
  publications {
    "${project.name}" (MavenPublication) {
      artifact integrationTestJar
    }
  }
}
